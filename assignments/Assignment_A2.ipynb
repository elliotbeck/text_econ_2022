{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment A2: Topic Modeling and Text ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Covering material from Notebooks 5 and 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-11-13 15:57:46--  https://raw.githubusercontent.com/mhjabreel/CharCnn_Keras/master/data/ag_news_csv/train.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 29470338 (28M) [text/plain]\n",
      "Saving to: 'train.csv'\n",
      "\n",
      "train.csv           100%[===================>]  28.10M  52.5MB/s    in 0.5s    \n",
      "\n",
      "2022-11-13 15:57:47 (52.5 MB/s) - 'train.csv' saved [29470338/29470338]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Import the AG news dataset (same as hw01)\n",
    "#Download them from here \n",
    "!wget https://raw.githubusercontent.com/mhjabreel/CharCnn_Keras/master/data/ag_news_csv/train.csv\n",
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "df = pd.read_csv('train.csv')\n",
    "\n",
    "df.columns = [\"label\", \"title\", \"lead\"]\n",
    "label_map = {1:\"world\", 2:\"sport\", 3:\"business\", 4:\"sci/tech\"}\n",
    "def replace_label(x):\n",
    "\treturn label_map[x]\n",
    "df[\"label\"] = df[\"label\"].apply(replace_label) \n",
    "df[\"text\"] = df[\"title\"] + \" \" + df[\"lead\"]\n",
    "df.head()\n",
    "\n",
    "\n",
    "import spacy\n",
    "dfs = df.sample(200)\n",
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Dimension Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.        ]\n",
      " [0.99869416]\n",
      " [0.99440343]\n",
      " [0.98841808]]\n",
      "Car Bomb Explodes in Baghdad BAGHDAD, Nov 2 - A car bomb exploded Tuesday in the busy commercial district of Azamiyah in northern Baghdad, causing casualties, the Interior Ministry said.\n",
      "\n",
      "Fourteen killed in Iraq blasts, gunfights BAGHDAD (Iraq): The top Fallujah negotiator in peace talks with the government dashed hopes of resuming talks soon despite his release Monday by US and Iraqi authorities, saying negotiations remain suspended.\n",
      "\n",
      "Nikkei Down at Midsession  TOKYO (Reuters) - Japan's Nikkei share average was lower at  midsession on Monday as caution over the yen's rise offset  optimism about the post-election outlook for Wall Street.\n",
      "\n",
      "Dahlan Bows Out of Palestinian Elections (AP) AP - Gaza strongman Mohammed Dahlan, once seen as a possible successor to Yasser Arafat, said Tuesday he will not run in the Jan. 9 elections and instead endorsed the interim Palestinian leader, Mahmoud Abbas.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=3,svd_solver='randomized')\n",
    "\n",
    "##TODO reduce the vectorized data using PCA\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "hv = CountVectorizer()\n",
    "X = hv.fit_transform(dfs[\"text\"]) \n",
    "X = np.array(X.todense())  # type: ignore\n",
    "X_pca = pca.fit_transform(X)\n",
    "##TODO compute again cosine similarity with the reduced version for the first 200 snippets\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarities = cosine_similarity(X_pca, X_pca[0,:].reshape(1,-1))\n",
    "##TODO for the first snippet, show again its three most similar snippets\n",
    "# ind = np.argpartition(similarities.reshape(1, -1), -3)[-3:]\n",
    "ind = (-similarities.reshape(1, -1)).argsort()\n",
    "\n",
    "# only keep top 3\n",
    "ind = ind[0][:4]\n",
    "\n",
    "# similarity scores of top three\n",
    "print(similarities[ind])\n",
    "\n",
    "# print orignal sentence and the three most similar snippets \n",
    "for i in ind:\n",
    "    print(str(dfs.iloc[i,3]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the cosine similarity between docs before and after PCA reduction. Did the results change? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling with LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this part you will need to use LDA Mallet. If you cannot have Mallet run, you can use the simple LDA algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "##TODO create a dictionary with the pre-processed tokenized text and filter it according to frequencies and keeping 1000 vocabularies\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "docs = list(nlp.pipe(dfs[\"text\"]))\n",
    "dfs[\"text_clean\"] = [[chunk.text.lower() for chunk in doc if not \n",
    "                      (chunk.is_punct or chunk.is_stop)] for doc in docs]\n",
    "# dfs[\"text_clean\"] = dfs[\"text_clean\"].str.join(\" \")\n",
    "common_dictionary = Dictionary(dfs[\"text_clean\"], prune_at=1000)\n",
    "\n",
    "##TODO create the doc_term_matrix\n",
    "common_corpus = [common_dictionary.doc2bow(text) for text in dfs[\"text_clean\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.030*\"161\" + 0.009*\"16\" + 0.009*\"181\" + 0.008*\"186\" + 0.006*\"320\" + 0.005*\"176\" + 0.005*\"65\" + 0.005*\"890\" + 0.004*\"32\" + 0.004*\"97\"'), (1, '0.019*\"36\" + 0.007*\"320\" + 0.005*\"958\" + 0.005*\"908\" + 0.004*\"1024\" + 0.004*\"281\" + 0.004*\"1661\" + 0.004*\"1076\" + 0.004*\"1095\" + 0.004*\"1858\"'), (2, '0.009*\"65\" + 0.008*\"161\" + 0.005*\"249\" + 0.005*\"205\" + 0.005*\"173\" + 0.005*\"2439\" + 0.004*\"735\" + 0.004*\"253\" + 0.004*\"1158\" + 0.004*\"17\"'), (3, '0.009*\"1194\" + 0.006*\"65\" + 0.006*\"36\" + 0.006*\"1006\" + 0.005*\"210\" + 0.005*\"2485\" + 0.005*\"320\" + 0.005*\"445\" + 0.005*\"114\" + 0.005*\"285\"'), (4, '0.009*\"36\" + 0.006*\"1322\" + 0.006*\"2232\" + 0.006*\"1318\" + 0.005*\"825\" + 0.005*\"176\" + 0.004*\"127\" + 0.004*\"16\" + 0.004*\"320\" + 0.004*\"47\"'), (5, '0.017*\"36\" + 0.013*\"161\" + 0.008*\"16\" + 0.005*\"799\" + 0.005*\"757\" + 0.004*\"2392\" + 0.004*\"65\" + 0.004*\"409\" + 0.004*\"664\" + 0.004*\"1338\"'), (6, '0.007*\"36\" + 0.005*\"176\" + 0.004*\"127\" + 0.004*\"446\" + 0.004*\"445\" + 0.004*\"297\" + 0.004*\"16\" + 0.004*\"439\" + 0.004*\"2113\" + 0.004*\"2456\"'), (7, '0.009*\"65\" + 0.007*\"617\" + 0.006*\"320\" + 0.006*\"138\" + 0.006*\"333\" + 0.006*\"36\" + 0.005*\"304\" + 0.004*\"937\" + 0.004*\"205\" + 0.004*\"473\"'), (8, '0.009*\"161\" + 0.008*\"181\" + 0.007*\"36\" + 0.007*\"606\" + 0.007*\"285\" + 0.006*\"344\" + 0.004*\"1025\" + 0.004*\"667\" + 0.004*\"445\" + 0.004*\"186\"'), (9, '0.025*\"161\" + 0.010*\"36\" + 0.008*\"16\" + 0.006*\"181\" + 0.006*\"539\" + 0.005*\"863\" + 0.005*\"541\" + 0.004*\"481\" + 0.004*\"963\" + 0.004*\"17\"')]\n"
     ]
    }
   ],
   "source": [
    "##TODO train a LDA Mallet model with 5, 10 and 15 topics\n",
    "lda5 = LdaModel(common_corpus, num_topics=5)\n",
    "lda10 = LdaModel(common_corpus, num_topics=10)\n",
    "lda15 = LdaModel(common_corpus, num_topics=15)\n",
    "##TODO compute the coherence score for each of these model and print the topics from the model with highest coherence score\n",
    "coherence5 = CoherenceModel(model=lda5, texts=dfs[\"text_clean\"], \n",
    "                            dictionary=common_dictionary, coherence='c_v')\n",
    "coherence10 = CoherenceModel(model=lda10, texts=dfs[\"text_clean\"], \n",
    "                             dictionary=common_dictionary, coherence='c_v')\n",
    "coherence15 = CoherenceModel(model=lda15, texts=dfs[\"text_clean\"], \n",
    "                             dictionary=common_dictionary, coherence='c_v')\n",
    "print(coherence5.get_coherence())\n",
    "print(coherence10.get_coherence()) ## highest coherence score\n",
    "print(coherence15.get_coherence())\n",
    "print(lda10.show_topics(num_topics=10, num_words=10,\n",
    "                        log=False, formatted=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elliotbeck/opt/anaconda3/lib/python3.9/site-packages/pyLDAvis/_prepare.py:246: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  default_term_info = default_term_info.sort_values(\n",
      "/Users/elliotbeck/opt/anaconda3/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/elliotbeck/opt/anaconda3/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/elliotbeck/opt/anaconda3/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/elliotbeck/opt/anaconda3/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/elliotbeck/opt/anaconda3/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/elliotbeck/opt/anaconda3/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/elliotbeck/opt/anaconda3/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/elliotbeck/opt/anaconda3/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el12982140636666617520494848102\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el12982140636666617520494848102_data = {\"mdsDat\": {\"x\": [-0.11672447336240638, -0.08011068157926027, -0.06715901333220799, 0.036064812100502594, 0.03428821380070764, 0.0911871028562897, 0.04516596870946406, 0.0395607362547767, 0.04664209013602795, -0.028914755583894263], \"y\": [-0.025811612183172798, -0.03049779654042588, 0.05638202650623335, 0.14141894571852837, 0.029134720638204496, -0.08042177678388494, -0.03500625864368776, -0.02329247376365206, 0.015150580448262022, -0.04705635539640492], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [14.558275171191315, 12.667915291864626, 12.28667805710963, 10.865963924559342, 10.287109856890314, 9.30749121620838, 7.940299705052173, 7.8007027152623944, 7.557557868742555, 6.728006193119274]}, \"tinfo\": {\"Term\": [\" \", \"ap\", \"jobs\", \"39;s\", \"reuters\", \"u.s.\", \"stocks\", \"earnings\", \"today\", \"military\", \"shanghai\", \"=\", \"rss\", \"oil\", \"data\", \"canas\", \"inca\", \"darfur\", \"soccer\", \"time\", \"ultimate\", \"quot\", \"iraqi\", \"open\", \"india\", \"group\", \"tuesday\", \"iraq\", \"music\", \"2004\", \"park\", \"suicide\", \"detroit\", \"wilkinson\", \"bobsled\", \"governor\", \"yudhoyono\", \"soft\", \"galapagos\", \"meters\", \"days\", \"pistons\", \"guerrillas\", \"soldiers\", \"station\", \"ivory\", \"manipur\", \"indonesia\", \"coast\", \"indonesian\", \"rebel\", \"capital\", \"police\", \"patch\", \"away\", \"tax\", \"heart\", \"supporters\", \"offices\", \"fed\", \"set\", \"run\", \" \", \"u.s.\", \"kill\", \"reuters\", \"said\", \"killed\", \"american\", \"saturday\", \"iraq\", \"new\", \"week\", \"post\", \"hostage\", \"york\", \"ap\", \"monday\", \"tuesday\", \"gaza\", \"sunday\", \"oct.\", \"team\", \"39;s\", \"patent\", \"israelis\", \"rumsfeld\", \"offside\", \"meteor\", \"normal\", \"provisioning\", \"human\", \"veritas\", \"=\", \"sees\", \"realnetworks\", \"music\", \"web\", \"systinet\", \"eye\", \"australia\", \"ceo\", \"gaming\", \"argosy\", \"penn\", \"galaxy\", \"nuclear\", \"peaks\", \"displaced\", \"heavenly\", \"dr\", \"utility\", \"allocation\", \"comet\", \"\\\\$1.4\", \"football\", \"adding\", \"called\", \"server\", \"francisco\", \"kicks\", \"shower\", \" \", \"microsoft\", \"darfur\", \"announced\", \"soccer\", \"said\", \"reuters\", \"39;s\", \"tuesday\", \"strike\", \"says\", \"software\", \"year\", \"network\", \"ap\", \"official\", \"game\", \"new\", \"billion\", \"wednesday\", \"united\", \"iraq\", \"thursday\", \"williams\", \"peoplesoft\", \"oracle\", \"india\", \"ferrari\", \"zte\", \"3000\", \"chelsea\", \"77\", \"martinsville\", \"bucks\", \"original\", \"maurice\", \"cooper\", \"quot;beg\", \"nascar\", \"barghouti\", \"judge\", \"gordon\", \"draw\", \"acer\", \"having\", \"cheaper\", \"hong\", \"kong\", \"opec\", \"ordered\", \"issued\", \"felon\", \"utah\", \"list\", \"home\", \"fees\", \"yesterday\", \"japan\", \"39;s\", \"quot\", \" \", \"said\", \"baghdad\", \"president\", \"39\", \"officials\", \"ap\", \"cuts\", \"company\", \"tuesday\", \"new\", \"people\", \"week\", \"united\", \"computer\", \"past\", \"million\", \"microsoft\", \"contract\", \"rail\", \"biggio\", \"moyes\", \"yukos\", \"lebanon\", \"escape\", \"decline\", \"marsh\", \"jardine\", \"eisner\", \"lloyd\", \"transport\", \"\\\\$920\", \"hardie\", \"insurance\", \"lafrentz\", \"cover\", \"criminal\", \"club\", \"kent\", \"james\", \"radio\", \"payments\", \"broker\", \"prey\", \"dinosaur\", \"signed\", \"moves\", \"repaired\", \"hilton\", \"scribes\", \"astros\", \"chief\", \"39;s\", \"m\", \"step\", \"new\", \"39\", \"company\", \"costs\", \"year\", \"deal\", \"software\", \"thursday\", \"microsoft\", \"american\", \"said\", \"world\", \"cisco\", \"bjp\", \"vic\", \"slowdown\", \"spacey\", \"allow\", \"advani\", \"cable\", \"adelphia\", \"alitalia\", \"sector\", \"muslims\", \"allies\", \"miller\", \"monetary\", \"pavano\", \"tour\", \"\\\\$1.49\", \"extends\", \"olivier\", \"communications\", \"disgusting\", \"hindu\", \"intended\", \"smell\", \"introduced\", \"wsj\", \"doesn\", \"loath\", \"krishna\", \"hardline\", \"54\", \"rescue\", \"sales\", \"warner\", \"unions\", \"drop\", \"chaos\", \"enron\", \"annan\", \"time\", \"gulf\", \"oil\", \"yankees\", \"bankrupt\", \"record\", \"world\", \"reuters\", \"old\", \"party\", \"job\", \"million\", \"stocks\", \" \", \"state\", \"39;s\", \"u.s.\", \"said\", \"thursday\", \"saturday\", \"plan\", \"chief\", \"jobs\", \"inca\", \"air\", \"abbey\", \"pictures\", \"slightly\", \"offsets\", \"alaska\", \"de\", \"output\", \"analysts\", \"central\", \"data\", \"6,000\", \"santander\", \"cameras\", \"water\", \"surveillance\", \"mayor\", \"johnson\", \"crawford\", \"hispano\", \"3,000\", \"tokyo--(business\", \"reu\", \"que\", \"october\", \"beats\", \"slowed\", \"et\", \"increased\", \"bank\", \"net\", \"worked\", \"minutes\", \"end\", \"bbc\", \"cut\", \"according\", \"prices\", \"quarter\", \"stocks\", \"running\", \"ap\", \"costs\", \"world\", \"year\", \"quot\", \"oil\", \"today\", \"new\", \"39;s\", \"announced\", \" \", \"national\", \"report\", \"inc.\", \"intel\", \"rss\", \"kanoodle\", \"ads\", \"shanghai\", \"lawsuits\", \"search\", \"feeds\", \"feedster\", \"includes\", \"canas\", \"inspections\", \"pension\", \"funds\", \"ouster\", \"sainsbury\", \"guillermo\", \"advances\", \"pretty\", \"channels\", \"healthcare\", \"unix\", \"display\", \"physical\", \"low\", \"drops\", \"completion\", \"lab\", \"kahney\", \"tb\", \"ticker\", \"shuttle\", \"pc\", \"trying\", \"servers\", \"store\", \"today\", \"struggling\", \"chiefs\", \"ibm\", \"programs\", \"takeover\", \"positions\", \"darfur\", \"open\", \"sudan\", \"39;s\", \"inc.\", \"iraq\", \"new\", \"said\", \"bid\", \"ap\", \"company\", \"microsoft\", \"world\", \"ron\", \"sonic\", \"fool\", \"wireless\", \"motley\", \"zook\", \"losses\", \"2003\", \"result\", \"yahoo\", \"plus\", \"cheering\", \"fec\", \"regulate\", \"flarion\", \"product\", \"fi\", \"organizing\", \"competes\", \"gators\", \"maintain\", \"finer\", \"euphoric\", \"remarks\", \"excitement\", \"25\", \"categories\", \"g\", \"gainesville\", \"unusual\", \"friendly\", \"earnings\", \"florida\", \"died\", \"military\", \"machine\", \"center\", \"ultimate\", \"action\", \"germany\", \"internet\", \"products\", \"political\", \"233;sum\", \"2004\", \"spam\", \"defense\", \"ap\", \"vehicle\", \"press\", \"john\", \"iran\", \"new\", \"technology\", \"wednesday\", \"39;s\", \"time\", \"soccer\", \" \", \"said\", \"company\", \"classic\", \"goaltender\", \"ousted\", \"overnight\", \"quarterfinals\", \"beckham\", \"gains\", \"tizbud\", \"google\", \"browser\", \"unit\", \"kabchi\", \"vento\", \"higher\", \"robby\", \"captain\", \"buybacks\", \"demonstrates\", \"weaknesses\", \"summer\", \"dashed\", \"super\", \"addressed\", \"sharon\", \"resuming\", \"tricks\", \"fourteen\", \"unrestricted\", \"glaring\", \"phish\", \"seeded\", \"california\", \"tokyo\", \"trophy\", \"players\", \"abuse\", \"winning\", \"ultimate\", \"narrower\", \"recent\", \"online\", \"members\", \"continental\", \"goal\", \"talks\", \"rangers\", \"open\", \"loss\", \"iraq\", \"stocks\", \"39;s\", \"iraqi\", \"said\", \"price\", \"wednesday\", \"united\", \"shares\", \"soccer\", \"gaza\", \"textile\", \"historic\", \"islamic\", \"jordan\", \"books\", \"hamas\", \"preparations\", \"stoudemire\", \"skycity\", \"casino\", \"jan.\", \"mylan\", \"bryant\", \"selection\", \"worsens\", \"makers\", \"48\", \"libraries\", \"housing\", \"petition\", \"moderate\", \"petitioned\", \"rejects\", \"chorus\", \"jewish\", \"rising\", \"rare\", \"manuscripts\", \"kingdom\", \"ceasefire\", \"chinese\", \"qaeda\", \"nasa\", \"resistance\", \"king\", \"elections\", \"border\", \"fire\", \"court\", \"group\", \"kobe\", \"hostages\", \"jury\", \"quickinfo\", \"ap\", \"iraqi\", \"9\", \"kill\", \"palestinian\", \"wednesday\", \" \", \"tuesday\", \"al\", \"u.s.\", \"inc.\", \"said\"], \"Freq\": [62.0, 21.0, 5.0, 46.0, 18.0, 12.0, 8.0, 5.0, 4.0, 6.0, 3.0, 5.0, 3.0, 8.0, 3.0, 3.0, 3.0, 6.0, 7.0, 9.0, 3.0, 7.0, 6.0, 6.0, 4.0, 5.0, 9.0, 13.0, 5.0, 8.0, 2.9461638157587204, 2.2022763530160376, 2.7183302031179033, 1.577600372123712, 1.5775398911987513, 1.5774622322596006, 1.5774516749383798, 1.5773992462075705, 1.5774062247758354, 1.5772192349338712, 1.57254770976243, 1.5667402884026749, 1.5650697265226972, 1.5617622430405307, 1.5587627112502496, 1.5150219400554243, 1.5138917698718404, 1.5044095060389597, 1.4762556354697867, 1.4707851537008627, 1.9624517707200089, 1.4627843146542217, 2.9214716729241283, 2.911319824413133, 1.4122150144123993, 1.8759277236838028, 1.888690809289326, 1.4002243131636587, 1.3489131374340055, 1.2950467320935897, 2.788117317265966, 3.500372540503648, 23.315903323741228, 6.0695549932921615, 2.3197698545097465, 6.660094323360703, 7.1696020974926435, 2.5010243869861357, 2.902820107204391, 3.047314226127121, 3.8728516533172446, 4.485742800724638, 2.9602485348309866, 1.9295787775650763, 1.8978103665100907, 2.5660483598870774, 3.782998829218782, 2.5478559481716267, 2.3948096833093455, 1.9770389467073326, 1.9972841311184881, 1.7901502045142708, 1.909070912686932, 1.9744497189434855, 2.125809956251639, 1.4403205386771274, 1.440217930407097, 1.4402185532190546, 1.4401677940445023, 1.4401299582180722, 1.4401312038419876, 1.4401190590088127, 1.439930191282641, 3.580638432374344, 1.3389779782476168, 2.1259925958582335, 3.383858814498203, 2.5538402768325414, 1.2714766062030116, 2.1802049513099684, 2.1259340515342102, 1.2303423676449718, 1.2092099686628477, 1.2006178105974525, 1.155109719363498, 1.1409959440356479, 0.7544765075442024, 0.7544614043542281, 0.7544582902944397, 0.7544393723812247, 0.7544385160147828, 0.7544361804699414, 0.7544303416078381, 0.754426838290576, 1.1011699219947502, 2.125580761451207, 1.1222496933664492, 1.428036662732485, 2.1116783529314995, 1.4400211218284646, 1.1196715632675636, 1.4401322937629135, 16.907945815809825, 4.01442758372209, 2.6459228690750165, 2.413199216090302, 2.650415523131862, 5.670135493135463, 4.021469095715808, 6.446042726589527, 2.590428766614342, 1.7340778950802505, 1.983585084700977, 1.9958519890197723, 2.331897654538547, 1.880266497632684, 2.4291276319083965, 1.6812483378775918, 1.7237010693500754, 2.342149762174193, 1.7465470575823077, 1.9584781333593162, 1.7636173991248392, 1.8269864916816212, 1.7292643371622016, 2.729612994484697, 2.0641563622287555, 2.063783047826196, 3.395511955982183, 1.3982631393830889, 1.3982447152904058, 1.3982246300090384, 1.3982015243846082, 1.398189291995204, 1.3981767575714934, 1.3981625619590983, 1.398140664471893, 1.398140664471893, 1.3981032122179147, 1.3980943022058794, 1.3980592662263511, 1.3980816167650156, 1.398022267023832, 1.3980095815829683, 1.397910363313356, 1.3978774415739716, 1.3116206721812111, 1.2812252987517534, 2.0639085430804545, 2.063711616712761, 1.2071230694208162, 1.187970469991104, 1.2150825794941649, 1.1694789481492585, 1.166467137555629, 2.493410387637215, 2.059230635744818, 2.0633615589517844, 2.479050921630985, 2.023401061076803, 11.0713079159345, 3.1998973232809758, 8.222041916777558, 5.350899572816887, 2.2422531561829815, 2.5319907397496584, 2.466814605780737, 1.9930920694589407, 2.603188078631389, 1.7320281127587829, 1.9299540629887841, 1.8554807090040075, 2.1580946191159356, 1.7569042622924664, 1.7676964011072451, 1.644234441798526, 1.5312160737151406, 1.4575718039010974, 1.5453284756588355, 1.5269199377426397, 2.156783375288907, 2.1567355626091027, 2.1567409048079633, 2.1565308228377615, 1.46115469349093, 1.4611392011142337, 1.461132656920629, 1.461108483470784, 1.4611095519105561, 1.4610983332929484, 1.4611130243398156, 1.461056397031891, 1.4610483837335997, 1.4610186009749506, 1.4610127245562037, 1.460994293970134, 1.4609840102373268, 1.4609693191904596, 1.4609248453849433, 1.4609248453849433, 1.4608700878466199, 1.4608528592552936, 1.4608284186955054, 1.46076644918872, 1.4607476179377354, 1.3029390635890956, 1.2966354024882987, 2.4200080706534326, 0.7654105534200738, 0.7653960627056638, 1.1484753935021867, 1.1387226752618727, 2.1567801699695903, 2.156601740527639, 10.785208219464167, 2.520301176516763, 2.156639269474636, 4.099713187980305, 2.96144793849589, 2.7294442552687435, 2.059992748553702, 2.018412010830448, 1.6037884648654661, 1.6010033094893774, 1.6416102979152754, 1.6476244118378156, 1.497147090540851, 1.485938489555992, 1.4808166563981802, 1.4610996688426636, 1.4714034600035326, 1.4713702062306386, 1.471295859392381, 1.471287261458705, 1.4712837211330736, 1.4712670310265261, 1.4711931899490729, 1.4711285790063016, 1.4711171993882008, 1.471024265840379, 1.4612798988607956, 1.4587106339740719, 1.4323848990198356, 1.7031522907478203, 1.2443700901197507, 1.9736336747408754, 1.1681404308273424, 0.7707419764974776, 0.7707227575869076, 0.770718964380874, 0.7707158665959466, 0.7707078376431756, 0.7706938027808514, 0.7706927912592425, 0.7706867221295889, 0.7706835611245608, 0.7706819806220468, 0.7706801472391307, 0.7706742677697787, 0.7706739516692759, 0.7706771126743038, 1.4711610741379888, 1.469988594153019, 1.4708922622704115, 1.4713114115371186, 1.4708295479306568, 1.1139141482139416, 1.0966257266346353, 1.0989407202769101, 3.729398997576028, 1.0726946426493784, 3.349120230377077, 1.0559863919329033, 1.2908759340528686, 2.1716051437182213, 3.5586887946009926, 4.266885924433397, 1.4712150641038664, 1.641795160111951, 1.4713530103632864, 2.3523595033896916, 2.169641527394854, 4.763200128600615, 1.8797668717944764, 3.7803475708558394, 2.1641851269557955, 1.764329496977498, 1.5281700526976012, 1.5087604703043342, 1.4714238168759126, 1.471254007685811, 4.357131365009731, 2.6862211464715813, 1.9044703486855308, 2.361964227405536, 1.3759069884258295, 1.3758659189761124, 1.3758642029823918, 1.3758561950116948, 1.3758454414510446, 1.3757967072293749, 1.3757841232754227, 1.8175527499379025, 2.6862680502999488, 1.3298809480461669, 2.165439474536813, 1.3177518468294618, 1.315437772097217, 1.3144404365467075, 1.2910294774130302, 1.222198452482284, 1.2078486265917439, 1.1560656560780715, 2.2432337066690313, 0.7208092827856922, 0.7207900064562289, 0.7207766789049976, 0.7207692429322077, 0.7207615781602549, 0.7207611205619294, 0.720759690567162, 1.3757817208842136, 1.375383724740577, 1.3758950908693655, 1.3757209747064985, 1.3755577265038628, 1.9204033503828504, 1.309361209532819, 2.9274697292850673, 2.0934654355071105, 2.0927396845628077, 2.526138837851201, 2.553978662378596, 1.4955665481627576, 2.960554088221451, 1.9300753773905803, 2.403481437084093, 2.246832717499386, 2.0019508039811296, 2.045204828104265, 1.711002810229726, 2.587640281602645, 2.95090265313837, 1.7467899736758985, 2.3531291477352148, 1.6033931871991849, 1.4508556453706907, 1.3880646895378808, 1.3759465706809886, 2.4268078613909014, 1.8348126223499766, 1.8346166510814599, 2.539194651218158, 1.2438434022064202, 1.243379531967745, 1.2433305391506158, 1.242827533215389, 1.2426275605414894, 2.334491730584065, 1.1988550159131481, 1.088831104762216, 1.0543380144076993, 1.0331931244348074, 1.0437643494805877, 0.9742865814809575, 0.9817721374048785, 0.6516454578245047, 0.6516427739550404, 0.6516413100262417, 0.6516363326683262, 0.6516320384771834, 0.6516311113222776, 0.6516271099168945, 0.6516256947857225, 0.6516218397732193, 0.6516116898668818, 0.6516009543890248, 0.6515988072934533, 0.6515977825432943, 1.2141396037144145, 1.2438326667285633, 1.235796185600072, 1.2439036184776726, 1.243901373786848, 2.105113021309916, 1.119096563936649, 0.8769025243635948, 1.2439253822191465, 1.2439799379657106, 1.3118015145177666, 0.8461169800846171, 1.8219673303083255, 1.8751208282738663, 1.2314287004220879, 3.7914475436109734, 1.8349152925563907, 2.013615129106289, 1.8362380986188787, 1.8417496929506585, 1.2128264595819978, 1.3959562422719576, 1.2716126675885961, 1.2436087832176184, 1.243925967790666, 1.2988402499967366, 1.298805541636364, 1.298779270667463, 1.2987159902314245, 1.2986708310111608, 1.2986324792317434, 1.2914968430328142, 1.2673601506565533, 1.2577505370468642, 1.2291378084948135, 0.6803837217492494, 0.6803805097877232, 0.6803800303904805, 0.680370778023696, 0.6803536635421311, 0.6803481504738399, 0.6803484381121855, 0.6803462328848691, 0.6803425415261001, 0.680335110868838, 0.6803344397126982, 0.6803320427264846, 0.6803242285514284, 0.6803196742776225, 0.6803194345790012, 0.6803171814119604, 0.6803086960807644, 0.6803103739711138, 0.6803058196973081, 0.6802984849194945, 1.6364501012919555, 2.493680829194271, 1.2988326755203017, 1.255944743513002, 2.740203957940635, 1.3999039003226494, 0.9443234961426554, 1.5060730354040381, 1.99160502875554, 1.2987353578800303, 1.8358887504477333, 1.298965468556534, 1.298764792870733, 0.9051848340911883, 2.5022946388513905, 0.8900912036631748, 1.0721903421882637, 3.7144446225327714, 0.8733169982610964, 1.1714872219158712, 1.1461866489137447, 1.2988929836934353, 2.5069643515132376, 1.2988242381288297, 1.767427180768856, 2.3768340793258704, 1.3751648932506402, 1.298608029972365, 1.387862400380111, 1.3476427934257682, 1.2985910593099728, 1.1751759876618189, 1.1750967517038964, 1.175084211429196, 1.175056529933931, 1.1750353508033258, 1.1749755290484583, 1.1749746001392212, 1.1748755784145488, 1.492574891987009, 1.4434545430941845, 1.0370971594257397, 1.051545506590126, 1.045301564480356, 1.5892540933451353, 0.6156287911886413, 0.6156166689230974, 0.6155757969166662, 0.6155743571073486, 0.6155632101965038, 0.615562513514576, 0.6155597732323266, 0.6155595410050173, 0.6155583334230091, 0.6155556395862216, 0.6155521097311207, 0.6155535959859001, 0.6155512272673456, 0.6155525741857393, 0.6155520632856589, 0.6155501590217229, 1.1748689831589656, 1.1752039478298548, 1.7344251436062812, 1.1749842607952867, 1.1752107288672855, 1.1302597890850716, 1.1749589944640382, 1.547079013036072, 0.8719539103310181, 1.0920384251617703, 1.0591287500379105, 0.9983151987778637, 0.8041652725006998, 1.1750293128932847, 1.1750265261655737, 1.1752265203243157, 1.7852721489889805, 1.6797122037607235, 2.190252238931614, 1.7343712668705307, 2.7571952714139965, 1.3643287538072149, 1.6244543657566979, 1.1869193511278433, 1.30466602820098, 1.2164716695961433, 1.175093036066948, 1.1750684199721657, 1.174980359376491, 1.181057255065233, 1.1810154114982043, 1.1809518191996962, 1.1809462786483307, 1.1808735072274112, 1.18083621187419, 1.1806651163402326, 1.1753308057972385, 1.1680505213030192, 1.1678446939545322, 1.511053900203792, 1.7058864793275617, 1.2559389644966261, 0.924137918898449, 0.6186647464409905, 0.618634025324091, 0.6186336945449049, 0.6186304694478414, 0.6186300146264607, 0.618627244350778, 0.6186218691890055, 0.6186112015602571, 0.6186042965447494, 0.6186008233632964, 0.6185915615460884, 0.618588832617804, 0.6185909413351147, 0.6185847392253773, 0.6185831680242437, 0.6185825064658718, 1.509660658272369, 1.180761042304172, 1.0826106710337615, 1.0517464921362687, 0.840100737767415, 1.8767036625999238, 1.0427744374952634, 1.1808774765776433, 1.0046993550378143, 1.73850527641718, 0.8000800121379267, 1.1809519018944927, 0.7855025734110022, 0.9612446452888894, 3.3016168741341247, 1.5770216894361189, 1.0452028528892665, 1.1808043743775376, 1.323510453917467, 1.8144467196657135, 2.867241947211188, 1.4471594349092995, 1.1808989772247331, 1.2486337888686605, 1.1972933860203436, 1.186178130338462], \"Total\": [62.0, 21.0, 5.0, 46.0, 18.0, 12.0, 8.0, 5.0, 4.0, 6.0, 3.0, 5.0, 3.0, 8.0, 3.0, 3.0, 3.0, 6.0, 7.0, 9.0, 3.0, 7.0, 6.0, 6.0, 4.0, 5.0, 9.0, 13.0, 5.0, 8.0, 3.6449462045490586, 2.8940373349578157, 3.6225630947219947, 2.1514874464803992, 2.1514219641305985, 2.151347760010387, 2.151344271146742, 2.1512836640826523, 2.151296558909566, 2.1511080910192955, 2.1505059579164167, 2.150532147746807, 2.148833057637396, 2.1479531370218914, 2.1473806550491576, 2.1357738314285406, 2.1466659779421793, 2.1463282247731947, 2.1257958057972357, 2.144145497309687, 2.87149637125832, 2.1430106335992347, 4.313814345857364, 4.305766825682422, 2.1164731009421, 2.822164279881654, 2.852524274535977, 2.1244781151703727, 2.131469323352965, 2.080538646438749, 4.734401595010235, 6.076397712414602, 62.479257009965586, 12.386983227026379, 4.02512460844523, 18.8299076777265, 28.223641028722895, 5.393916288675315, 7.362692407560834, 8.33968373211666, 13.620076106244603, 22.11441140510039, 8.967410823397412, 3.5322278963595117, 3.4755984293084667, 7.578299829746291, 21.199497233354762, 8.749540488162102, 9.370417988355543, 5.275755560107386, 7.389405145572777, 4.756752857616767, 7.357693474152322, 46.9273991029425, 2.706255282020234, 2.0207483367851937, 2.0206472916203957, 2.0206502126998895, 2.0205996733341247, 2.020559054023904, 2.0205634798253915, 2.020552019884446, 2.0203664450908265, 5.303608869376222, 2.002869578016746, 3.2665064969415547, 5.235758979423248, 3.964883119576239, 1.99087095062677, 3.4159734597510054, 3.4020870785070545, 1.9834767040501684, 1.9782568341664832, 1.9767476012466956, 1.9683039748145525, 2.0069436243060306, 1.3349005567765642, 1.3348859657065186, 1.3348813871013712, 1.3348642469182255, 1.334863947463374, 1.3348614413049082, 1.3348557475504899, 1.3348521338664938, 1.9583774377004748, 3.8840061514814153, 2.0112912255595172, 2.588935680333916, 4.022316727901999, 2.6863981288514887, 2.0511100684888746, 2.7442819238225966, 62.479257009965586, 10.809903401840625, 6.54444955797421, 5.9788129506424355, 7.131977040189356, 28.223641028722895, 18.8299076777265, 46.9273991029425, 9.370417988355543, 4.1751648670798005, 5.7695370313229395, 6.136931868062509, 10.655326631980868, 5.557494686469842, 21.199497233354762, 4.0312190250760125, 4.587880097088471, 22.11441140510039, 5.25429909296, 12.181041105456728, 8.554399520564292, 13.620076106244603, 9.48052709555442, 3.312309532856679, 2.646588938906923, 2.6462219542574283, 4.674868045111198, 1.9806934609971651, 1.9806744381873644, 1.9806559479171828, 1.9806343582114672, 1.9806204122229791, 1.9806082263352385, 1.980595946976031, 1.9805718223858633, 1.9805759739910673, 1.9805353767661864, 1.9805256481489388, 1.980492034578275, 1.9805279001497158, 1.980454600242688, 1.9804460040878211, 1.980347795557773, 1.980314482350085, 1.9743977808627111, 1.9720017996434351, 3.2653758278815994, 3.265105611284062, 1.9670536543280501, 1.9575492383248778, 2.0040494928681714, 1.976860891772321, 1.9874075646837426, 4.679123096950312, 3.9659961096571874, 4.037180267627435, 5.284610241874774, 4.075323237517464, 46.9273991029425, 7.876252033852323, 62.479257009965586, 28.223641028722895, 5.309489349900838, 7.149977220241642, 10.79260955308271, 6.123295737213214, 21.199497233354762, 4.70006630820917, 9.169816122790053, 9.370417988355543, 22.11441140510039, 7.8969498603617065, 8.967410823397412, 8.554399520564292, 5.766967290228067, 3.421011610527826, 7.981995583917157, 10.809903401840625, 2.7362306369770457, 2.736175485590113, 2.736183440138919, 2.735981569792848, 2.0405879979726733, 2.0405728475833387, 2.0405691580063845, 2.0405435877907045, 2.0405469052861323, 2.04053238192298, 2.040555270643828, 2.0404907923983138, 2.040483328198081, 2.0404531415047074, 2.0404530918315236, 2.0404307740501926, 2.040425921399608, 2.040405621318393, 2.040365339904664, 2.0403667573571616, 2.040309713952255, 2.040297943782859, 2.0402685092744677, 2.0402089804462467, 2.0401879138589054, 2.009488600906049, 2.008257316941131, 4.01364081025348, 1.3448402265494634, 1.3448278325661198, 2.0269005773969515, 2.0427793589482994, 4.121977203273022, 4.137212666236963, 46.9273991029425, 6.088739240012831, 4.877224709215496, 22.11441140510039, 10.79260955308271, 9.169816122790053, 6.4638733400609585, 10.655326631980868, 4.619388049927745, 6.136931868062509, 9.48052709555442, 10.809903401840625, 7.362692407560834, 28.223641028722895, 12.651910138714607, 2.7640437154146738, 2.050351796071293, 2.0503193942614737, 2.050245236863034, 2.0502361345448925, 2.0502342438767074, 2.0502164169844534, 2.050145858448629, 2.0500821009284214, 2.0500726543962524, 2.049976935530696, 2.0507554603482316, 2.051105479913984, 2.0473580631439887, 2.740826017549249, 2.048623094779753, 3.392955795860168, 2.034984717629519, 1.3496871982246528, 1.3496675198950534, 1.3496641040134298, 1.349662679856223, 1.3496516554847275, 1.3496394061297148, 1.3496399793295506, 1.3496338861993793, 1.349629654599238, 1.3496292299718473, 1.349628347113454, 1.349618442670624, 1.349618444604159, 1.3496242054905518, 2.6676804151045848, 2.668350590954958, 2.705086075590379, 2.7459361588130102, 2.774618199763252, 2.0425534956634253, 2.0315773569611784, 2.042394040968763, 9.214086301576963, 2.0417676777946285, 8.69797907943654, 2.0114449495760236, 2.656532351422219, 5.893739885827278, 12.651910138714607, 18.8299076777265, 3.3389017369212595, 4.044147780593185, 3.3471143431488586, 7.981995583917157, 8.357486556495939, 62.479257009965586, 6.270714256496179, 46.9273991029425, 12.386983227026379, 28.223641028722895, 9.48052709555442, 8.33968373211666, 5.1780546680650845, 4.137212666236963, 5.22008937085072, 3.26972677199062, 2.5966945196203968, 3.238772299920319, 1.9594000196606676, 1.959356251088134, 1.9593544204011377, 1.9593505280151362, 1.9593392260710958, 1.9592926500364212, 1.959278166302006, 2.593943038238157, 3.8881981348868684, 1.9622101591930854, 3.2198427903443547, 1.9602054038596595, 1.960267566908833, 1.9604597510037487, 1.9603999679360238, 1.9687861742089923, 1.9673380210866411, 1.9383458945945358, 3.892844317621522, 1.3042952794120661, 1.3042765511117542, 1.3042633397068304, 1.3042563178422386, 1.3042485581619712, 1.3042485485080328, 1.304246363759856, 2.519450573613261, 2.5217682131746217, 2.5749224512577222, 2.6591567977270105, 2.659690112257921, 3.9181873379422187, 2.556420931372272, 6.64737751034259, 4.559722486674278, 5.28173477421133, 7.2977571300215685, 8.357486556495939, 3.131585566512996, 21.199497233354762, 6.4638733400609585, 12.651910138714607, 10.655326631980868, 7.876252033852323, 8.69797907943654, 4.922761088183977, 22.11441140510039, 46.9273991029425, 5.9788129506424355, 62.479257009965586, 7.439539968949424, 6.602035820035527, 10.14504165111132, 3.896322172075001, 3.0186441843443848, 2.4259691581351768, 2.426116941072163, 3.584110408564102, 1.833788380826385, 1.83384870929132, 1.8337797983372495, 1.8336354534131882, 1.8338003227894195, 3.572762182232899, 1.8457133899484908, 1.8529743410047872, 1.8571517009559837, 1.8596673753428303, 1.887273187683639, 1.8186783503038195, 1.861549210504092, 1.24142055106402, 1.2414188354874236, 1.2414170572741436, 1.2414115388343145, 1.2414081384911124, 1.2414065391943239, 1.2414034806605958, 1.2414047903671106, 1.2413977939512895, 1.241387637046694, 1.2413765694927275, 1.2413764149044406, 1.241376335648385, 2.409199216801407, 2.4887617998410714, 2.4941825685100647, 2.5194617106098534, 2.5217307159419935, 4.922761088183977, 2.617854444161198, 1.891540529966106, 3.1696026927543057, 3.221726097258104, 3.6756088524390123, 1.8847255859536147, 6.54444955797421, 6.907652895255025, 3.892164590256945, 46.9273991029425, 10.14504165111132, 13.620076106244603, 22.11441140510039, 28.223641028722895, 4.6442639748798, 21.199497233354762, 9.169816122790053, 10.809903401840625, 12.651910138714607, 1.88600764012914, 1.8859760500411467, 1.885943830569521, 1.8858897404255623, 1.8858361977935, 1.88580376473013, 1.88635852876271, 1.8839963241412274, 1.8836253381218961, 1.8913176079217933, 1.2675450410872546, 1.2675421139186822, 1.2675425820686224, 1.2675333234002444, 1.2675181318592441, 1.267508905776651, 1.2675126592786476, 1.2675097246340692, 1.2675076452378586, 1.2674974468419014, 1.2674972654702326, 1.2674929669431456, 1.2674873730366536, 1.2674822864519368, 1.2674826175512592, 1.267480286959259, 1.2674697850184447, 1.2674763030330056, 1.2674689256166618, 1.2674595452206612, 3.117224542675494, 5.009504737030212, 2.5508438158387245, 2.5476389764453957, 6.4874701620963755, 3.0148601154386254, 1.9130689708050315, 3.584339004625485, 5.254821816917045, 3.028194360333529, 5.038690060789344, 3.1440438928898358, 3.188849400344265, 1.9287887171129525, 8.951107198751364, 1.917658008802928, 2.5843020922414905, 21.199497233354762, 1.9104785900248322, 3.239261541048455, 3.145354229964895, 4.5891001008678485, 22.11441140510039, 4.6134059835720915, 12.181041105456728, 46.9273991029425, 9.214086301576963, 7.131977040189356, 62.479257009965586, 28.223641028722895, 9.169816122790053, 1.7682374810964447, 1.7681593723755074, 1.7681516251136606, 1.768119760957634, 1.7681061360937576, 1.7680386940398636, 1.7680391277057006, 1.767946341310153, 2.3691559925022245, 2.3771837342753983, 1.7762433603846994, 1.805739292502383, 1.8079193519087833, 3.059019684139706, 1.2086843611207418, 1.2086694177629966, 1.2086295197559105, 1.2086301187689135, 1.2086182778889356, 1.2086173887248195, 1.2086133329524484, 1.2086133902526057, 1.208613965792921, 1.208612713514916, 1.208606103125607, 1.208609392525182, 1.2086052060275592, 1.2086081662520682, 1.2086075354804453, 1.208605910215146, 2.360113530139967, 2.3709313377116557, 3.732713470791681, 2.445744206484994, 2.463985440840566, 2.3629841064991033, 2.471681717484824, 3.584339004625485, 1.8417819894231529, 2.4526553355845038, 2.454442942869937, 2.3937696101370607, 1.7698353078610318, 3.0867012480586133, 3.093805323308401, 3.270753078656214, 6.907652895255025, 6.288681999234474, 13.620076106244603, 8.357486556495939, 46.9273991029425, 6.3152922815715895, 28.223641028722895, 4.3962502402785235, 12.181041105456728, 8.554399520564292, 4.579432463135342, 7.131977040189356, 5.275755560107386, 1.7738362208377905, 1.7737989844956925, 1.7737355666514554, 1.7737284586214876, 1.7736605408188217, 1.773623016313766, 1.773454896039671, 1.774693903796074, 1.7779538151181589, 1.7780526166005166, 2.378946789036175, 3.029817663118312, 2.3335357882735823, 1.7724002587695673, 1.211440180547089, 1.2114089550133036, 1.2114101614951496, 1.211408120481105, 1.211407250248337, 1.2114027777369833, 1.2113988162181772, 1.2113867750633278, 1.211381817518046, 1.2113773757898882, 1.2113696904863058, 1.2113653308014547, 1.2113696653360417, 1.2113626516615792, 1.2113599166836213, 1.211360885642133, 3.1637305983436654, 2.474437913578873, 2.38006577486276, 2.5030246837675563, 1.8485519195292388, 5.712766786090096, 2.5371955710493452, 3.1156070976700017, 2.4735612181749858, 5.623863569241853, 1.7716914967176982, 3.1941709644363847, 1.7717180157354695, 2.545838479979932, 21.199497233354762, 6.3152922815715895, 3.1240487358080586, 4.02512460844523, 5.114292093602301, 12.181041105456728, 62.479257009965586, 9.370417988355543, 5.221427705304449, 12.386983227026379, 10.14504165111132, 28.223641028722895], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -5.564, -5.855, -5.6445, -6.1886, -6.1886, -6.1887, -6.1887, -6.1887, -6.1887, -6.1888, -6.1918, -6.1955, -6.1966, -6.1987, -6.2006, -6.2291, -6.2298, -6.2361, -6.255, -6.2587, -5.9703, -6.2641, -5.5724, -5.5759, -6.2993, -6.0154, -6.0086, -6.3078, -6.3452, -6.3859, -5.6191, -5.3916, -3.4953, -4.8412, -5.803, -4.7483, -4.6746, -5.7278, -5.5788, -5.5302, -5.2905, -5.1436, -5.5592, -5.9872, -6.0038, -5.7021, -5.314, -5.7092, -5.7712, -5.9629, -5.9527, -6.0622, -5.9979, -5.9642, -5.7512, -6.1405, -6.1406, -6.1406, -6.1406, -6.1407, -6.1407, -6.1407, -6.1408, -5.2299, -6.2135, -5.7512, -5.2864, -5.5678, -6.2652, -5.726, -5.7512, -6.2981, -6.3154, -6.3226, -6.3612, -6.3735, -6.7871, -6.7871, -6.7871, -6.7872, -6.7872, -6.7872, -6.7872, -6.7872, -6.409, -5.7513, -6.3901, -6.1491, -5.7579, -6.1407, -6.3924, -6.1407, -3.6776, -5.1155, -5.5324, -5.6244, -5.5307, -4.7702, -5.1137, -4.6419, -5.5536, -5.9549, -5.8205, -5.8143, -5.6587, -5.874, -5.6179, -5.9859, -5.9609, -5.6543, -5.9478, -5.8332, -5.938, -5.9027, -5.9577, -5.4707, -5.7501, -5.7503, -5.2524, -6.1396, -6.1396, -6.1396, -6.1397, -6.1397, -6.1397, -6.1397, -6.1397, -6.1397, -6.1397, -6.1397, -6.1398, -6.1397, -6.1398, -6.1398, -6.1399, -6.1399, -6.2036, -6.227, -5.7502, -5.7503, -6.2866, -6.3026, -6.28, -6.3183, -6.3209, -5.5612, -5.7525, -5.7505, -5.567, -5.7701, -4.0705, -5.3117, -4.368, -4.7976, -5.6674, -5.5458, -5.5719, -5.7852, -5.5181, -5.9255, -5.8173, -5.8567, -5.7056, -5.9113, -5.9052, -5.9776, -6.0488, -6.0981, -6.0396, -6.0516, -5.5833, -5.5834, -5.5834, -5.5835, -5.9727, -5.9727, -5.9727, -5.9728, -5.9728, -5.9728, -5.9728, -5.9728, -5.9728, -5.9728, -5.9728, -5.9728, -5.9728, -5.9729, -5.9729, -5.9729, -5.9729, -5.9729, -5.973, -5.973, -5.973, -6.0873, -6.0922, -5.4682, -6.6193, -6.6193, -6.2135, -6.222, -5.5833, -5.5834, -3.9738, -5.4276, -5.5834, -4.941, -5.2663, -5.3479, -5.6293, -5.6496, -5.8796, -5.8813, -5.8563, -5.8526, -5.9484, -5.9559, -5.9594, -5.9728, -5.911, -5.911, -5.9111, -5.9111, -5.9111, -5.9111, -5.9111, -5.9112, -5.9112, -5.9113, -5.9179, -5.9197, -5.9379, -5.7647, -6.0786, -5.6173, -6.1418, -6.5576, -6.5576, -6.5576, -6.5576, -6.5577, -6.5577, -6.5577, -6.5577, -6.5577, -6.5577, -6.5577, -6.5577, -6.5577, -6.5577, -5.9112, -5.912, -5.9113, -5.9111, -5.9114, -6.1893, -6.205, -6.2029, -4.981, -6.227, -5.0885, -6.2427, -6.0419, -5.5217, -5.0278, -4.8463, -5.9111, -5.8014, -5.911, -5.4418, -5.5227, -4.7363, -5.6661, -4.9674, -5.5252, -5.7294, -5.8731, -5.8859, -5.911, -5.9111, -4.7253, -5.209, -5.5529, -5.3376, -5.878, -5.8781, -5.8781, -5.8781, -5.8781, -5.8781, -5.8781, -5.5997, -5.209, -5.9121, -5.4245, -5.9212, -5.923, -5.9237, -5.9417, -5.9965, -6.0083, -6.0521, -5.3892, -6.5245, -6.5245, -6.5246, -6.5246, -6.5246, -6.5246, -6.5246, -5.8781, -5.8784, -5.878, -5.8782, -5.8783, -5.5446, -5.9276, -5.123, -5.4583, -5.4587, -5.2704, -5.2595, -5.7946, -5.1118, -5.5396, -5.3202, -5.3876, -5.503, -5.4816, -5.6601, -5.2464, -5.115, -5.6394, -5.3414, -5.725, -5.825, -5.8692, -5.878, -5.1517, -5.4313, -5.4314, -5.1064, -5.8201, -5.8204, -5.8205, -5.8209, -5.821, -5.1905, -5.8569, -5.9532, -5.9854, -6.0056, -5.9954, -6.0643, -6.0567, -6.4665, -6.4665, -6.4665, -6.4665, -6.4665, -6.4665, -6.4666, -6.4666, -6.4666, -6.4666, -6.4666, -6.4666, -6.4666, -5.8442, -5.8201, -5.8266, -5.82, -5.82, -5.2939, -5.9258, -6.1696, -5.82, -5.82, -5.7669, -6.2054, -5.4384, -5.4096, -5.8301, -4.7055, -5.4313, -5.3383, -5.4306, -5.4276, -5.8453, -5.7047, -5.798, -5.8203, -5.82, -5.7591, -5.7591, -5.7591, -5.7592, -5.7592, -5.7592, -5.7647, -5.7836, -5.7912, -5.8142, -6.4056, -6.4056, -6.4056, -6.4057, -6.4057, -6.4057, -6.4057, -6.4057, -6.4057, -6.4057, -6.4057, -6.4057, -6.4057, -6.4057, -6.4057, -6.4057, -6.4057, -6.4057, -6.4057, -6.4058, -5.528, -5.1068, -5.7591, -5.7926, -5.0125, -5.6841, -6.0778, -5.611, -5.3316, -5.7591, -5.413, -5.759, -5.7591, -6.1202, -5.1033, -6.137, -5.9508, -4.7083, -6.156, -5.8623, -5.8841, -5.759, -5.1015, -5.7591, -5.451, -5.1548, -5.702, -5.7592, -5.6928, -5.7222, -5.7593, -5.8275, -5.8275, -5.8275, -5.8276, -5.8276, -5.8276, -5.8276, -5.8277, -5.5884, -5.6218, -5.9524, -5.9386, -5.9446, -5.5256, -6.474, -6.474, -6.4741, -6.4741, -6.4741, -6.4741, -6.4741, -6.4741, -6.4741, -6.4741, -6.4741, -6.4741, -6.4741, -6.4741, -6.4741, -6.4741, -5.8277, -5.8274, -5.4382, -5.8276, -5.8274, -5.8664, -5.8276, -5.5525, -6.1259, -5.9008, -5.9314, -5.9906, -6.2068, -5.8276, -5.8276, -5.8274, -5.4093, -5.4702, -5.2049, -5.4382, -4.9747, -5.6782, -5.5037, -5.8175, -5.7229, -5.7929, -5.8275, -5.8275, -5.8276, -5.7062, -5.7062, -5.7063, -5.7063, -5.7063, -5.7064, -5.7065, -5.7111, -5.7173, -5.7174, -5.4598, -5.3385, -5.6447, -5.9515, -6.3528, -6.3528, -6.3528, -6.3528, -6.3528, -6.3529, -6.3529, -6.3529, -6.3529, -6.3529, -6.3529, -6.3529, -6.3529, -6.3529, -6.3529, -6.3529, -5.4607, -5.7064, -5.7932, -5.8221, -6.0468, -5.2431, -5.8307, -5.7063, -5.8679, -5.3196, -6.0956, -5.7063, -6.114, -5.9121, -4.6782, -5.4171, -5.8284, -5.7064, -5.5923, -5.2768, -4.8193, -5.503, -5.7063, -5.6506, -5.6925, -5.7019], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.7142, 1.6538, 1.6398, 1.6168, 1.6167, 1.6167, 1.6167, 1.6167, 1.6167, 1.6167, 1.614, 1.6103, 1.61, 1.6083, 1.6067, 1.5836, 1.5778, 1.5717, 1.5624, 1.5501, 1.5464, 1.5451, 1.5373, 1.5357, 1.5224, 1.5186, 1.5147, 1.5101, 1.4695, 1.4529, 1.3975, 1.3755, 0.9413, 1.2136, 1.3759, 0.8877, 0.5567, 1.1584, 0.9963, 0.9202, 0.6695, 0.3317, 0.8187, 1.3224, 1.3219, 0.8441, 0.2036, 0.6933, 0.5628, 0.9455, 0.6188, 0.9497, 0.5779, -1.2413, 1.8247, 1.7275, 1.7275, 1.7275, 1.7275, 1.7275, 1.7275, 1.7275, 1.7274, 1.6733, 1.6634, 1.6366, 1.6296, 1.6262, 1.6177, 1.6171, 1.5959, 1.5885, 1.5738, 1.5675, 1.5331, 1.5014, 1.4955, 1.4955, 1.4955, 1.4955, 1.4955, 1.4955, 1.4955, 1.4955, 1.4904, 1.4633, 1.4827, 1.4712, 1.4217, 1.4426, 1.4608, 1.4213, 0.759, 1.0755, 1.1605, 1.1588, 1.0762, 0.4612, 0.5223, 0.081, 0.7804, 1.1874, 0.9984, 0.9428, 0.5467, 0.9824, -0.1003, 1.1916, 1.0872, -0.1791, 0.9647, 0.2384, 0.487, 0.0572, 0.3646, 1.9032, 1.8481, 1.8481, 1.7769, 1.7484, 1.7484, 1.7484, 1.7484, 1.7484, 1.7484, 1.7484, 1.7484, 1.7484, 1.7484, 1.7484, 1.7484, 1.7484, 1.7484, 1.7484, 1.7484, 1.7484, 1.6877, 1.6654, 1.6379, 1.6379, 1.6084, 1.5972, 1.5963, 1.5717, 1.5638, 1.4672, 1.4412, 1.4254, 1.3397, 1.3965, 0.6524, 1.1959, 0.0686, 0.4338, 1.2346, 1.0586, 0.6207, 0.9742, -0.0006, 1.0984, 0.5382, 0.4772, -0.2303, 0.5937, 0.4727, 0.4475, 0.7706, 1.2435, 0.4547, 0.1394, 1.9816, 1.9816, 1.9816, 1.9815, 1.8855, 1.8855, 1.8855, 1.8855, 1.8855, 1.8855, 1.8855, 1.8855, 1.8855, 1.8855, 1.8855, 1.8855, 1.8855, 1.8855, 1.8855, 1.8855, 1.8855, 1.8855, 1.8855, 1.8854, 1.8854, 1.7863, 1.782, 1.7136, 1.6559, 1.6559, 1.6515, 1.6351, 1.5718, 1.568, 0.7491, 1.3375, 1.4035, 0.5342, 0.9264, 1.0077, 1.076, 0.5558, 1.1616, 0.8758, 0.466, 0.3384, 0.6267, -0.7246, 0.0743, 1.582, 1.9425, 1.9425, 1.9425, 1.9425, 1.9425, 1.9425, 1.9424, 1.9424, 1.9424, 1.9424, 1.9354, 1.9335, 1.9171, 1.7985, 1.7757, 1.7325, 1.7192, 1.714, 1.714, 1.714, 1.714, 1.714, 1.714, 1.714, 1.714, 1.714, 1.714, 1.714, 1.714, 1.714, 1.714, 1.6791, 1.6781, 1.665, 1.6503, 1.6396, 1.668, 1.6577, 1.6545, 1.3698, 1.6306, 1.3199, 1.6299, 1.5526, 1.2759, 1.0059, 0.7897, 1.4547, 1.3728, 1.4524, 1.0525, 0.9257, -0.2996, 1.0695, -0.2445, 0.5297, -0.4981, 0.4491, 0.5645, 1.0161, 1.2404, 2.1936, 2.1778, 2.0643, 2.0586, 2.0208, 2.0208, 2.0208, 2.0208, 2.0208, 2.0208, 2.0208, 2.0187, 2.0046, 1.9854, 1.9776, 1.9772, 1.9754, 1.9746, 1.9566, 1.8976, 1.8865, 1.8575, 1.8231, 1.7813, 1.7813, 1.7813, 1.7813, 1.7813, 1.7813, 1.7813, 1.7693, 1.7681, 1.7476, 1.7153, 1.715, 1.6613, 1.7053, 1.5543, 1.5959, 1.4486, 1.3135, 1.1888, 1.6353, 0.4057, 1.1657, 0.7135, 0.8178, 1.0046, 0.9268, 1.3176, 0.2289, -0.3921, 1.1439, -0.9047, 0.8397, 0.8591, 0.3853, 1.3335, 2.315, 2.2539, 2.2538, 2.1886, 2.145, 2.1446, 2.1446, 2.1443, 2.1441, 2.1077, 2.1017, 2.0015, 1.9671, 1.9455, 1.9409, 1.9091, 1.8934, 1.8887, 1.8887, 1.8887, 1.8887, 1.8887, 1.8887, 1.8887, 1.8887, 1.8887, 1.8887, 1.8887, 1.8887, 1.8887, 1.848, 1.8396, 1.831, 1.8274, 1.8265, 1.6837, 1.6834, 1.7645, 1.5979, 1.5816, 1.5029, 1.7323, 1.2545, 1.2293, 1.3824, 0.0174, 0.8232, 0.6216, 0.0447, -0.1962, 1.1905, -0.1872, 0.5576, 0.3708, 0.2137, 2.178, 2.178, 2.178, 2.1779, 2.1779, 2.1779, 2.1721, 2.1545, 2.1471, 2.12, 1.9288, 1.9288, 1.9288, 1.9288, 1.9288, 1.9288, 1.9287, 1.9287, 1.9287, 1.9287, 1.9287, 1.9287, 1.9287, 1.9287, 1.9287, 1.9287, 1.9287, 1.9287, 1.9287, 1.9287, 1.9065, 1.8534, 1.876, 1.8437, 1.6891, 1.7838, 1.845, 1.6839, 1.5808, 1.7044, 1.5413, 1.667, 1.6527, 1.7944, 1.2764, 1.7834, 1.6712, 0.8092, 1.7681, 1.5339, 1.5415, 1.2888, 0.3738, 1.2834, 0.6206, -0.4319, 0.6488, 0.8477, -1.2561, -0.4908, 0.5963, 2.1741, 2.174, 2.174, 2.174, 2.174, 2.174, 2.174, 2.174, 2.1206, 2.0837, 2.0445, 2.0419, 2.0348, 1.9278, 1.908, 1.908, 1.9079, 1.9079, 1.9079, 1.9079, 1.9079, 1.9079, 1.9079, 1.9079, 1.9079, 1.9079, 1.9079, 1.9079, 1.9079, 1.9079, 1.8851, 1.8808, 1.8162, 1.8495, 1.8423, 1.8451, 1.839, 1.7424, 1.8349, 1.7735, 1.7422, 1.7081, 1.7938, 1.6168, 1.6145, 1.5591, 1.2296, 1.2625, 0.7551, 1.0101, -0.2518, 1.0503, -0.2724, 1.2732, 0.3487, 0.6321, 1.2224, 0.7794, 1.0808, 2.2922, 2.2921, 2.2921, 2.2921, 2.2921, 2.2921, 2.292, 2.2868, 2.2788, 2.2785, 2.245, 2.1245, 2.0794, 2.0477, 2.0269, 2.0269, 2.0269, 2.0269, 2.0269, 2.0269, 2.0269, 2.0268, 2.0268, 2.0268, 2.0268, 2.0268, 2.0268, 2.0268, 2.0268, 2.0268, 1.959, 1.959, 1.9111, 1.8318, 1.9103, 1.5857, 1.8097, 1.7287, 1.7979, 1.5249, 1.9039, 1.7039, 1.8855, 1.7249, 0.8393, 1.3115, 1.604, 1.4725, 1.3471, 0.7948, -0.3826, 0.8309, 1.2124, 0.4043, 0.562, -0.4705]}, \"token.table\": {\"Topic\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 8, 2, 3, 4, 6, 7, 8, 10, 2, 8, 8, 3, 6, 3, 1, 2, 3, 4, 6, 7, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 5, 6, 3, 4, 6, 10, 2, 10, 2, 5, 4, 6, 7, 9, 3, 6, 8, 3, 1, 3, 4, 8, 2, 9, 5, 7, 7, 5, 6, 1, 3, 5, 7, 10, 6, 5, 5, 2, 5, 1, 4, 5, 9, 10, 6, 5, 1, 2, 6, 7, 1, 2, 3, 6, 7, 8, 9, 10, 2, 1, 4, 2, 4, 1, 1, 2, 3, 9, 6, 10, 5, 3, 6, 7, 6, 9, 1, 3, 5, 6, 7, 4, 1, 2, 3, 9, 5, 1, 10, 1, 10, 4, 9, 9, 10, 3, 9, 5, 7, 9, 2, 10, 6, 7, 9, 1, 9, 10, 8, 10, 8, 6, 2, 7, 5, 3, 8, 3, 4, 5, 7, 1, 10, 10, 1, 4, 9, 4, 1, 2, 5, 1, 3, 4, 5, 7, 8, 9, 8, 7, 2, 3, 7, 8, 9, 9, 4, 3, 2, 4, 6, 9, 10, 4, 10, 4, 6, 4, 1, 2, 4, 6, 3, 4, 5, 2, 3, 5, 7, 9, 6, 8, 1, 6, 2, 4, 5, 8, 4, 2, 8, 9, 1, 3, 8, 4, 5, 2, 7, 5, 2, 3, 1, 5, 7, 6, 8, 10, 4, 3, 4, 5, 10, 1, 6, 5, 4, 6, 8, 8, 5, 2, 4, 8, 1, 7, 7, 3, 4, 3, 3, 8, 8, 1, 8, 10, 8, 3, 8, 8, 2, 8, 9, 9, 2, 3, 6, 8, 7, 8, 8, 9, 1, 2, 2, 6, 2, 8, 1, 5, 9, 8, 10, 9, 2, 5, 9, 9, 9, 3, 1, 1, 6, 8, 10, 1, 7, 5, 10, 4, 5, 3, 7, 1, 2, 4, 9, 4, 5, 6, 10, 3, 5, 8, 3, 8, 1, 1, 3, 10, 10, 2, 2, 6, 7, 1, 2, 4, 5, 6, 7, 8, 9, 10, 6, 7, 6, 3, 4, 1, 1, 7, 4, 2, 6, 9, 5, 2, 6, 8, 9, 5, 2, 3, 8, 1, 2, 3, 7, 8, 9, 10, 1, 2, 9, 10, 10, 2, 3, 1, 4, 10, 1, 2, 3, 4, 10, 5, 6, 6, 6, 7, 8, 6, 10, 3, 10, 9, 7, 7, 4, 2, 1, 10, 1, 3, 5, 9, 10, 10, 10, 3, 8, 5, 7, 4, 7, 4, 10, 1, 3, 8, 4, 5, 3, 4, 5, 6, 9, 10, 8, 7, 1, 3, 4, 5, 8, 9, 8, 10, 1, 10, 4, 3, 3, 6, 8, 9, 2, 1, 1, 2, 3, 4, 7, 1, 2, 3, 8, 5, 1, 3, 4, 5, 6, 9, 10, 5, 6, 10, 1, 2, 3, 5, 6, 8, 9, 2, 5, 8, 4, 4, 2, 9, 5, 2, 10, 9, 7, 10, 3, 1, 2, 4, 5, 6, 8, 6, 1, 2, 4, 6, 1, 2, 3, 4, 5, 6, 7, 8, 10, 2, 2, 1, 4, 8, 6, 1, 1, 2, 6, 1, 3, 4, 5, 6, 6, 2, 3, 4, 5, 6, 7, 8, 5, 6, 5, 2, 9, 3, 1, 3, 5, 7, 9, 3, 3, 8, 3, 9, 7, 6, 9, 1, 3, 6, 10, 1, 4, 5, 7, 1, 3, 1, 3, 2, 5, 4, 6, 7, 2, 2, 7, 1, 2, 3, 5, 8, 9, 10, 3, 10, 10, 9, 7, 6, 1, 5, 6, 9, 4, 9, 8, 1, 3, 4, 8, 7, 1, 2, 10, 2, 3, 4, 7, 9, 4, 6, 8, 7, 4, 2, 3, 9, 3, 5, 6, 8, 4, 8, 10, 4, 5, 7, 2, 5, 10, 1, 3, 5, 6, 8, 9, 9, 6, 1, 2, 10, 2, 3, 6, 8, 3, 4, 4, 1, 9, 10, 2, 9, 1, 9, 3, 5, 6, 7, 10, 8, 10, 8, 4, 1, 3, 5, 6, 7, 5, 5, 10, 8, 9, 6, 1, 2, 3, 5, 6, 10, 10, 9, 8, 7, 2, 1, 7, 9, 10, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 7, 5, 8, 6, 7, 1, 3, 5, 6, 8, 2, 3, 6, 7, 10, 4, 7, 5, 7, 9, 2, 10, 2, 3, 2, 7, 1, 9, 7, 9, 1, 3, 4, 9, 9, 1, 2, 7, 10, 3, 4, 10, 6, 5, 6, 5, 2, 4, 8, 9, 1, 1, 2, 3, 4, 6, 1, 8, 5, 8, 1, 2, 3, 4, 5, 1, 1, 2, 4, 5, 1, 5, 6, 9, 10, 2, 7, 10, 1, 2, 4, 1, 7, 2, 5, 7, 1, 9, 1, 2, 3, 4, 5, 10, 9, 1, 6, 2, 7, 10, 2, 9, 1, 7, 1, 4, 5, 8, 9, 2, 3, 5, 8, 10, 1, 2, 3, 4, 5, 6, 7, 1, 5, 6, 8, 9, 9, 6, 7, 9, 1, 2, 9, 6, 5, 6, 4, 9, 9, 6, 7, 1, 2, 3, 6, 10, 1, 5, 7, 8, 10, 8, 9, 4, 5, 9, 1, 2, 3, 6, 7, 9, 7, 9, 8, 3, 2, 6, 8, 9, 2, 5, 5, 6, 6, 9, 2, 8, 1, 2, 3, 4, 5, 6, 8, 9, 10, 1, 2, 3, 4, 5, 1, 3, 1, 9, 8, 5, 6, 1, 2, 4, 5, 6, 7, 9, 10, 5, 8, 5, 1, 2, 4, 5, 6, 8, 9, 1, 3, 9, 1, 3, 4, 5, 6, 1, 4, 8, 3], \"Freq\": [0.3681221752738104, 0.2720903034632512, 0.12804249574741233, 0.01600531196842654, 0.0800265598421327, 0.03201062393685308, 0.01600531196842654, 0.01600531196842654, 0.01600531196842654, 0.04801593590527962, 0.5307865982465889, 0.11171802301054948, 0.11171802301054948, 0.11171802301054948, 0.11171802301054948, 0.11171802301054948, 0.33515406903164846, 0.11171802301054948, 0.5184601045866853, 0.5184601045866853, 0.7889669056700235, 0.25688158025569, 0.51376316051138, 0.5048832438827043, 0.1853119943015762, 0.0926559971507881, 0.1853119943015762, 0.2779679914523643, 0.0926559971507881, 0.0926559971507881, 0.0926559971507881, 0.042619025094757346, 0.12785707528427204, 0.23440463802116543, 0.23440463802116543, 0.08523805018951469, 0.06392853764213602, 0.08523805018951469, 0.042619025094757346, 0.06392853764213602, 0.021309512547378673, 0.8254842428973664, 0.7409469954167924, 0.5096294070820769, 0.5048923023456245, 0.32009743911416366, 0.32009743911416366, 0.32009743911416366, 0.7542034298751852, 0.1885508574687963, 0.5106267978527159, 0.49140418173010375, 0.49008721624578067, 0.617517940377965, 0.423193705471662, 0.423193705471662, 0.21931159251960736, 0.4386231850392147, 0.21931159251960736, 0.5049703008853811, 0.19030140979864674, 0.19030140979864674, 0.19030140979864674, 0.3806028195972935, 0.49719304061589187, 0.8273940466540464, 0.48778534261975637, 0.8243625713755369, 0.5371869807992926, 0.48775338628438214, 0.770209966897598, 0.19151849962110937, 0.19151849962110937, 0.19151849962110937, 0.19151849962110937, 0.19151849962110937, 0.5103732005589736, 0.48778759028640406, 0.487541966901642, 0.7491446186863542, 0.487749145243589, 0.4074596402967025, 0.13581988009890084, 0.13581988009890084, 0.13581988009890084, 0.13581988009890084, 0.5103920500923188, 0.48962148338705147, 0.16725728137933266, 0.3345145627586653, 0.3345145627586653, 0.16725728137933266, 0.18868371999438266, 0.09434185999719133, 0.141512789995787, 0.141512789995787, 0.047170929998595665, 0.18868371999438266, 0.047170929998595665, 0.141512789995787, 0.5058814789350546, 0.24260202099273095, 0.4852040419854619, 0.5878744293863473, 0.29393721469317363, 0.4724841527893138, 0.18834202954351464, 0.18834202954351464, 0.3766840590870293, 0.18834202954351464, 0.39654715083473624, 0.39654715083473624, 0.37643057479222236, 0.5049158862767882, 0.39117188712079815, 0.39117188712079815, 0.766725018587916, 0.5655984811707142, 0.2153193714674415, 0.2153193714674415, 0.2153193714674415, 0.2153193714674415, 0.2153193714674415, 0.7309451444887254, 0.19032034193482728, 0.38064068386965455, 0.19032034193482728, 0.19032034193482728, 0.4877211812705086, 0.9296177288067294, 0.5638057435377931, 0.39413595522966144, 0.39413595522966144, 0.4901509283566698, 0.4206658431914667, 0.4285342461963393, 0.4285342461963393, 0.5048985390113504, 0.8273833988449625, 0.48777017297525965, 0.4217751834876698, 0.4217751834876698, 0.3862591131931952, 0.3862591131931952, 0.5101506189254413, 0.5597909678807794, 0.2798954839403897, 0.46663324218810687, 0.8273560870356084, 0.5624130527205172, 0.7889734428544564, 0.825517822023705, 0.5227203071404131, 0.7710269541456194, 0.5041652356985317, 0.8055299077264005, 0.48958326042530315, 0.507098928703216, 0.7889284221953307, 0.5048887473117503, 0.48341725730505336, 0.24170862865252668, 0.5286696130259068, 0.3160825389252607, 0.6321650778505215, 0.8255065844761563, 0.36178877867348624, 0.36178877867348624, 0.5655348960140366, 0.49010796534211143, 0.4704120674586479, 0.7491466467551197, 0.7409250916775137, 0.10905344083341718, 0.21810688166683437, 0.32716032250025157, 0.10905344083341718, 0.10905344083341718, 0.10905344083341718, 0.10905344083341718, 0.7889498763633426, 0.8055435613568026, 0.17340136499377526, 0.3468027299875505, 0.17340136499377526, 0.17340136499377526, 0.17340136499377526, 0.5650243248952747, 0.7309325365238859, 0.5049139801949903, 0.15470600170989263, 0.30941200341978525, 0.30941200341978525, 0.15470600170989263, 0.15470600170989263, 0.4042754198490419, 0.4042754198490419, 0.4900986301703371, 0.5083010592392553, 0.49010830582268416, 0.15043526540265084, 0.15043526540265084, 0.15043526540265084, 0.4513057962079526, 0.4255259115189046, 0.2127629557594523, 0.2127629557594523, 0.45840371652717415, 0.15280123884239138, 0.15280123884239138, 0.30560247768478277, 0.8273944798847788, 0.7715656188100323, 0.2571885396033441, 0.9300136987008215, 0.5103761445154237, 0.21647889053521746, 0.4329577810704349, 0.21647889053521746, 0.21647889053521746, 0.49006549332410954, 0.38695166598447145, 0.38695166598447145, 0.8273829887828544, 0.8281429257563361, 0.3925202939842184, 0.3925202939842184, 0.497944158631597, 0.7409258734979084, 0.7491302295939944, 0.8055368488364065, 0.7409442369745205, 0.7491400167787048, 0.5049618063267245, 0.36040994760480066, 0.36040994760480066, 0.80553902140516, 0.1996205318677532, 0.3992410637355064, 0.1996205318677532, 0.4900626875372427, 0.1750465295441222, 0.1750465295441222, 0.1750465295441222, 0.3500930590882444, 0.25522005809073617, 0.5104401161814723, 0.4922283646121131, 0.49005935235098325, 0.7667263086072323, 0.7889624948327447, 0.788965454951936, 0.7409124138655067, 0.585484642537528, 0.292742321268764, 0.7889281308151443, 0.48064476077466606, 0.5453217452317525, 0.5453646732989198, 0.4953952678400852, 0.2476976339200426, 0.5058524877304175, 0.5048736817137557, 0.7889467554265759, 0.7889590128549059, 0.32096473292407357, 0.32096473292407357, 0.32096473292407357, 0.7889433491047277, 0.39202713776154785, 0.39202713776154785, 0.5302384852564872, 0.5149322431523883, 0.25746612157619414, 0.25746612157619414, 0.827400043465639, 0.3722456434361531, 0.3722456434361531, 0.3207981928506524, 0.6415963857013048, 0.538458974291245, 0.7889693855475257, 0.7889739778144619, 0.565598342440335, 0.9296719188793505, 0.4982700998119886, 0.43593118339540443, 0.21796559169770222, 0.50549553664064, 0.7889562243234506, 0.37909262042445546, 0.18954631021222773, 0.18954631021222773, 0.3302297940644268, 0.3302297940644268, 0.8273984487466234, 0.32397045247866213, 0.32397045247866213, 0.32397045247866213, 0.5655598786078363, 0.4220912439555459, 0.5049367657264621, 0.9296497931093873, 0.17781370185955792, 0.17781370185955792, 0.17781370185955792, 0.35562740371911583, 0.9307377289694923, 0.5498498400406784, 0.4897716869923852, 0.5638176719641155, 0.4900872281765584, 0.7409501581710366, 0.5064835514366568, 0.8055310615722987, 0.7011333848597457, 0.7491398487214562, 0.32690211350543563, 0.6538042270108713, 0.493364110283224, 0.7409319256092417, 0.5159037934295935, 0.563761738923483, 0.5042869293618334, 0.2521434646809167, 0.2521434646809167, 0.6124869250647613, 0.30624346253238066, 0.575440471814788, 0.3130702805622839, 0.3130702805622839, 0.3130702805622839, 0.8254862266962668, 0.49491425618291646, 0.3154969555919404, 0.3154969555919404, 0.3154969555919404, 0.09857031980646987, 0.19714063961293973, 0.09857031980646987, 0.09857031980646987, 0.09857031980646987, 0.19714063961293973, 0.09857031980646987, 0.09857031980646987, 0.09857031980646987, 0.9175078559159213, 0.5453156418245613, 0.39691193408325276, 0.6417293431709346, 0.21390978105697817, 0.9318239293113441, 0.46638626028631214, 0.5417959285801722, 0.49009258864246136, 0.25665228793630435, 0.25665228793630435, 0.25665228793630435, 0.7409386503226398, 0.19846428098086735, 0.19846428098086735, 0.3969285619617347, 0.19846428098086735, 0.7409416807220499, 0.21790764594803438, 0.21790764594803438, 0.21790764594803438, 0.2936841151839129, 0.14684205759195645, 0.07342102879597823, 0.14684205759195645, 0.07342102879597823, 0.14684205759195645, 0.07342102879597823, 0.31669159728934837, 0.15834579864467418, 0.15834579864467418, 0.31669159728934837, 0.5637818955662308, 0.49486617496907054, 0.49898967244008136, 0.9364287409881193, 0.4901244953204865, 0.8407081693535043, 0.2453793090064588, 0.2453793090064588, 0.4907586180129176, 0.4900681845870089, 0.8255118217449776, 0.2987648157425156, 0.2987648157425156, 0.7662704057015252, 0.31792921460905244, 0.31792921460905244, 0.31792921460905244, 0.5079271751802983, 0.5637841548627931, 0.5049345740505531, 0.5644239044354264, 0.5537897990878882, 0.8055573341525506, 0.8244127891293491, 0.4901216678829188, 0.48754087621281844, 0.49687902724893096, 0.24843951362446548, 0.5561821577206506, 0.18539405257355018, 0.18539405257355018, 0.18539405257355018, 0.5409639780389099, 0.8255184823497643, 0.5644323528405693, 0.6125376138180914, 0.3062688069090457, 0.7409501592325611, 0.8055501522304798, 0.4900937542069946, 0.5453191930190747, 0.49005846627054034, 0.8254856336961442, 0.21371525802596747, 0.42743051605193494, 0.21371525802596747, 0.4900781732147092, 0.7409447216626496, 0.15901583195361615, 0.15901583195361615, 0.15901583195361615, 0.15901583195361615, 0.3180316639072323, 0.15901583195361615, 0.5301219173090677, 0.8055398712655967, 0.16423761317094812, 0.16423761317094812, 0.49271283951284434, 0.16423761317094812, 0.33169034771436223, 0.33169034771436223, 0.7889563372186109, 0.8254850650241545, 0.9316773175476628, 0.8255166185191022, 0.4900646965818101, 0.5048954087453839, 0.5049036306266482, 0.5100999879391114, 0.41775114687947884, 0.41775114687947884, 0.4949025842164634, 0.9297533714599654, 0.18501552933946253, 0.37003105867892505, 0.18501552933946253, 0.18501552933946253, 0.09250776466973126, 0.1541432908381744, 0.1541432908381744, 0.1541432908381744, 0.46242987251452317, 0.4884343476608913, 0.12528195355242866, 0.2505639071048573, 0.12528195355242866, 0.2505639071048573, 0.12528195355242866, 0.12528195355242866, 0.12528195355242866, 0.3759836514002974, 0.3759836514002974, 0.825491973916455, 0.3428751491645671, 0.11429171638818902, 0.11429171638818902, 0.11429171638818902, 0.11429171638818902, 0.11429171638818902, 0.11429171638818902, 0.36485351262615534, 0.7297070252523107, 0.5302687482454934, 0.7435827544850881, 0.7309990761931295, 0.5729828305294659, 0.1909942768431553, 0.48762517976189784, 0.3300528649538574, 0.6601057299077148, 0.5429524263689866, 0.42015645557428444, 0.42015645557428444, 0.5049250300130288, 0.13441691343466433, 0.13441691343466433, 0.13441691343466433, 0.13441691343466433, 0.26883382686932866, 0.13441691343466433, 0.3883612104556972, 0.35987438816075834, 0.35987438816075834, 0.17993719408037917, 0.17993719408037917, 0.1808775249192232, 0.0904387624596116, 0.0904387624596116, 0.1808775249192232, 0.0452193812298058, 0.13565814368941742, 0.0904387624596116, 0.13565814368941742, 0.0452193812298058, 0.4949125332459447, 0.749119471801509, 0.4204548901037592, 0.2102274450518796, 0.2102274450518796, 0.7667204569531239, 0.4691599306843052, 0.2480639215531446, 0.4961278431062892, 0.2480639215531446, 0.16331074684547445, 0.3266214936909489, 0.16331074684547445, 0.16331074684547445, 0.16331074684547445, 0.5103721866691532, 0.4948902059915907, 0.11496923490701022, 0.11496923490701022, 0.34490770472103066, 0.22993846981402044, 0.11496923490701022, 0.11496923490701022, 0.2994996794730718, 0.2994996794730718, 0.740923216465754, 0.4074244230875123, 0.4074244230875123, 0.5083745416906801, 0.14476697297383248, 0.14476697297383248, 0.14476697297383248, 0.28953394594766496, 0.28953394594766496, 0.7557945004508254, 0.5108428336932788, 0.7889485820621224, 0.5049046889879341, 0.56556235664219, 0.5377305712080095, 0.5103882771067462, 0.5655725489196436, 0.19553048236156578, 0.19553048236156578, 0.19553048236156578, 0.19553048236156578, 0.8230574147447948, 0.24727088480760773, 0.49454176961521545, 0.24727088480760773, 0.29231119734367417, 0.29231119734367417, 0.6967400050801704, 0.2322466683600568, 0.7390285806692225, 0.48813273781213024, 0.4901458672048753, 0.40180623154206985, 0.40180623154206985, 0.7491276601074515, 0.5080516082858679, 0.5396728804446065, 0.253262339936953, 0.1266311699684765, 0.253262339936953, 0.1266311699684765, 0.1266311699684765, 0.1266311699684765, 0.1266311699684765, 0.7556896995216896, 0.8254892743997962, 0.8255001792864405, 0.8273995613855539, 0.8055378866048206, 0.5103603092609859, 0.9300023727129468, 0.19312271965133118, 0.19312271965133118, 0.19312271965133118, 0.40584655388988794, 0.40584655388988794, 0.7889266003062392, 0.6954402205280243, 0.23181340684267476, 0.3135927334454995, 0.3135927334454995, 0.5305812195965016, 0.5662148815656256, 0.2831074407828128, 0.5638711208461603, 0.13986058545319446, 0.41958175635958345, 0.13986058545319446, 0.13986058545319446, 0.13986058545319446, 0.3087123368483327, 0.3087123368483327, 0.3087123368483327, 0.8055287945272868, 0.4976390508257248, 0.2274665784122073, 0.2274665784122073, 0.2274665784122073, 0.1893317333696144, 0.1893317333696144, 0.3786634667392288, 0.7889490917519525, 0.3180617173511703, 0.3180617173511703, 0.3180617173511703, 0.31039261868073276, 0.31039261868073276, 0.31039261868073276, 0.49491144919951524, 0.40413218473267826, 0.40413218473267826, 0.13702840231366326, 0.13702840231366326, 0.13702840231366326, 0.41108520694098977, 0.13702840231366326, 0.13702840231366326, 0.5655769071698832, 0.7667163291002091, 0.39279789659235675, 0.39279789659235675, 0.39279789659235675, 0.12696394118699805, 0.3808918235609941, 0.2539278823739961, 0.12696394118699805, 0.5049164604026367, 0.4901315662395859, 0.73094726947627, 0.6114799717078301, 0.30573998585391504, 0.8255118388841226, 0.6122749187465598, 0.3061374593732799, 0.6965009672373637, 0.40772137262477826, 0.16967155310072432, 0.33934310620144864, 0.16967155310072432, 0.16967155310072432, 0.16967155310072432, 0.7889338935227612, 0.8255035576222053, 0.7889656610502226, 0.7435896073714209, 0.30293685985927254, 0.15146842992963627, 0.15146842992963627, 0.15146842992963627, 0.15146842992963627, 0.3748574957996967, 0.39951663540720606, 0.39951663540720606, 0.5308911383603858, 0.827399429320996, 0.7667085628025809, 0.3717490345574106, 0.21242801974709177, 0.05310700493677294, 0.21242801974709177, 0.05310700493677294, 0.05310700493677294, 0.8255147927490936, 0.8273458581632999, 0.5302205456238381, 0.6625491041218484, 0.4948909214126533, 0.6582847583902641, 0.16457118959756603, 0.16457118959756603, 0.16457118959756603, 0.31932705613836854, 0.31932705613836854, 0.24801902748395133, 0.21258773784338686, 0.17715644820282236, 0.035431289640564474, 0.07086257928112895, 0.035431289640564474, 0.07086257928112895, 0.035431289640564474, 0.07086257928112895, 0.035431289640564474, 0.5298649959772695, 0.3747633475862393, 0.3747633475862393, 0.6211483386696978, 0.3105741693348489, 0.3597258716714648, 0.11990862389048826, 0.23981724778097652, 0.11990862389048826, 0.11990862389048826, 0.34664826469471594, 0.17332413234735797, 0.17332413234735797, 0.17332413234735797, 0.17332413234735797, 0.4895291288408348, 0.5453012535513052, 0.48781036638401054, 0.42370843064515407, 0.42370843064515407, 0.49928363333083636, 0.5642066429702614, 0.49722588629741754, 0.24861294314870877, 0.39691017957877317, 0.39691017957877317, 0.6336598067983531, 0.21121993559945101, 0.837027785983269, 0.279009261994423, 0.21836767067754562, 0.21836767067754562, 0.21836767067754562, 0.21836767067754562, 0.8273949039405488, 0.36439404833708505, 0.36439404833708505, 0.4150756786844959, 0.4150756786844959, 0.24915034684851267, 0.49830069369702534, 0.562444306200126, 0.510371709812673, 0.48774653003464324, 0.7667250242631503, 0.7409383356417477, 0.4206407259999184, 0.14021357533330614, 0.14021357533330614, 0.14021357533330614, 0.9296774913469338, 0.16294787387230847, 0.32589574774461694, 0.16294787387230847, 0.32589574774461694, 0.16294787387230847, 0.9311190107122046, 0.5302294268149285, 0.4877486954555008, 0.5214694149892954, 0.3189429334829106, 0.1594714667414553, 0.1594714667414553, 0.1594714667414553, 0.3189429334829106, 0.9313672428301801, 0.20503463744668235, 0.20503463744668235, 0.4100692748933647, 0.20503463744668235, 0.11965319875061482, 0.23930639750122965, 0.3589595962518444, 0.23930639750122965, 0.11965319875061482, 0.3965530473488521, 0.3965530473488521, 0.5634774525685797, 0.23951149998525, 0.4790229999705, 0.23951149998525, 0.3819922082491549, 0.3819922082491549, 0.2569264420377413, 0.2569264420377413, 0.2569264420377413, 0.6910760880108523, 0.8273917033868541, 0.27065778105268223, 0.13532889052634112, 0.13532889052634112, 0.13532889052634112, 0.13532889052634112, 0.13532889052634112, 0.8273944406581458, 0.4707038367960806, 0.5100844327398221, 0.5022927275548312, 0.27206376960824685, 0.27206376960824685, 0.3232265432042883, 0.3232265432042883, 0.7086759669723652, 0.805557434468399, 0.27182431655056405, 0.13591215827528202, 0.13591215827528202, 0.13591215827528202, 0.13591215827528202, 0.21675959227540492, 0.21675959227540492, 0.21675959227540492, 0.21675959227540492, 0.5637499044459109, 0.1054793673306326, 0.2109587346612652, 0.1054793673306326, 0.2109587346612652, 0.2109587346612652, 0.1054793673306326, 0.8055574858994623, 0.10852948054424594, 0.43411792217698375, 0.10852948054424594, 0.10852948054424594, 0.10852948054424594, 0.5656280265038705, 0.4062760642194413, 0.4062760642194413, 0.20313803210972065, 0.26790162379860016, 0.26790162379860016, 0.5358032475972003, 0.7666975536787709, 0.5894565447743972, 0.2947282723871986, 0.49007996594761905, 0.8273971774376762, 0.408873502530828, 0.40093296001076784, 0.40093296001076784, 0.21343765053868094, 0.3201564758080214, 0.21343765053868094, 0.10671882526934047, 0.10671882526934047, 0.48437944009716405, 0.16145981336572135, 0.08072990668286067, 0.08072990668286067, 0.08072990668286067, 0.5579829356037636, 0.5579829356037636, 0.3641745263415998, 0.3641745263415998, 0.5629859186544234, 0.2337978247558012, 0.2337978247558012, 0.2337978247558012, 0.1168989123779006, 0.1168989123779006, 0.1168989123779006, 0.8055346423950595, 0.8273980169280432, 0.7889798169659946, 0.5031680555966539, 0.7491414232644544, 0.5234290534430968, 0.5234290534430968, 0.5531220178290641, 0.4949597150704235, 0.4877288888740189, 0.3696740037308248, 0.3696740037308248, 0.5101344412777847, 0.8273910946859714, 0.7566427330954048, 0.2522142443651349, 0.164189578106264, 0.164189578106264, 0.082094789053132, 0.082094789053132, 0.082094789053132, 0.082094789053132, 0.164189578106264, 0.082094789053132, 0.164189578106264, 0.33454472635206134, 0.22302981756804088, 0.22302981756804088, 0.11151490878402044, 0.11151490878402044, 0.9295894351007177, 0.9057124553853728, 0.4045828364250706, 0.4045828364250706, 0.5302536932908622, 0.3760590578392287, 0.3760590578392287, 0.15807889702599434, 0.07903944851299717, 0.07903944851299717, 0.3161577940519887, 0.15807889702599434, 0.07903944851299717, 0.07903944851299717, 0.8254637876947403, 0.7409440038548518, 0.5287319251993927, 0.4971550428018336, 0.09384977434653226, 0.18769954869306452, 0.18769954869306452, 0.09384977434653226, 0.18769954869306452, 0.09384977434653226, 0.09384977434653226, 0.18922871398842062, 0.37845742797684123, 0.18922871398842062, 0.39586715587900345, 0.13195571862633448, 0.13195571862633448, 0.13195571862633448, 0.13195571862633448, 0.929651300734833, 0.4900548278209522, 0.5302778680914905, 0.5048785306257402], \"Term\": [\" \", \" \", \" \", \" \", \" \", \" \", \" \", \" \", \" \", \" \", \"2003\", \"2004\", \"2004\", \"2004\", \"2004\", \"2004\", \"2004\", \"2004\", \"233;sum\", \"233;sum\", \"25\", \"3,000\", \"3,000\", \"3000\", \"39\", \"39\", \"39\", \"39\", \"39\", \"39\", \"39\", \"39;s\", \"39;s\", \"39;s\", \"39;s\", \"39;s\", \"39;s\", \"39;s\", \"39;s\", \"39;s\", \"39;s\", \"48\", \"54\", \"6,000\", \"77\", \"9\", \"9\", \"9\", \"=\", \"=\", \"\\\\$1.4\", \"\\\\$1.49\", \"\\\\$920\", \"abbey\", \"abuse\", \"abuse\", \"according\", \"according\", \"according\", \"acer\", \"action\", \"action\", \"action\", \"action\", \"adding\", \"addressed\", \"adelphia\", \"ads\", \"advances\", \"advani\", \"air\", \"al\", \"al\", \"al\", \"al\", \"al\", \"alaska\", \"alitalia\", \"allies\", \"allocation\", \"allow\", \"american\", \"american\", \"american\", \"american\", \"american\", \"analysts\", \"annan\", \"announced\", \"announced\", \"announced\", \"announced\", \"ap\", \"ap\", \"ap\", \"ap\", \"ap\", \"ap\", \"ap\", \"ap\", \"argosy\", \"astros\", \"astros\", \"australia\", \"australia\", \"away\", \"baghdad\", \"baghdad\", \"baghdad\", \"baghdad\", \"bank\", \"bank\", \"bankrupt\", \"barghouti\", \"bbc\", \"bbc\", \"beats\", \"beckham\", \"bid\", \"bid\", \"bid\", \"bid\", \"bid\", \"biggio\", \"billion\", \"billion\", \"billion\", \"billion\", \"bjp\", \"bobsled\", \"books\", \"border\", \"border\", \"broker\", \"browser\", \"bryant\", \"bryant\", \"bucks\", \"buybacks\", \"cable\", \"california\", \"california\", \"called\", \"called\", \"cameras\", \"canas\", \"canas\", \"capital\", \"captain\", \"casino\", \"categories\", \"ceasefire\", \"center\", \"central\", \"ceo\", \"channels\", \"chaos\", \"cheaper\", \"cheering\", \"chelsea\", \"chief\", \"chief\", \"chiefs\", \"chinese\", \"chinese\", \"chorus\", \"cisco\", \"cisco\", \"classic\", \"club\", \"coast\", \"comet\", \"communications\", \"company\", \"company\", \"company\", \"company\", \"company\", \"company\", \"company\", \"competes\", \"completion\", \"computer\", \"computer\", \"computer\", \"computer\", \"computer\", \"continental\", \"contract\", \"cooper\", \"costs\", \"costs\", \"costs\", \"costs\", \"costs\", \"court\", \"court\", \"cover\", \"crawford\", \"criminal\", \"cut\", \"cut\", \"cut\", \"cut\", \"cuts\", \"cuts\", \"cuts\", \"darfur\", \"darfur\", \"darfur\", \"darfur\", \"dashed\", \"data\", \"data\", \"days\", \"de\", \"deal\", \"deal\", \"deal\", \"deal\", \"decline\", \"defense\", \"defense\", \"demonstrates\", \"detroit\", \"died\", \"died\", \"dinosaur\", \"disgusting\", \"displaced\", \"display\", \"doesn\", \"dr\", \"draw\", \"drop\", \"drop\", \"drops\", \"earnings\", \"earnings\", \"earnings\", \"eisner\", \"elections\", \"elections\", \"elections\", \"elections\", \"end\", \"end\", \"enron\", \"escape\", \"et\", \"euphoric\", \"excitement\", \"extends\", \"eye\", \"eye\", \"fec\", \"fed\", \"feeds\", \"feedster\", \"fees\", \"fees\", \"felon\", \"ferrari\", \"fi\", \"finer\", \"fire\", \"fire\", \"fire\", \"flarion\", \"florida\", \"florida\", \"fool\", \"football\", \"football\", \"football\", \"fourteen\", \"francisco\", \"francisco\", \"friendly\", \"friendly\", \"funds\", \"g\", \"gainesville\", \"gains\", \"galapagos\", \"galaxy\", \"game\", \"game\", \"gaming\", \"gators\", \"gaza\", \"gaza\", \"gaza\", \"germany\", \"germany\", \"glaring\", \"goal\", \"goal\", \"goal\", \"goaltender\", \"google\", \"gordon\", \"governor\", \"group\", \"group\", \"group\", \"group\", \"guerrillas\", \"guillermo\", \"gulf\", \"hamas\", \"hardie\", \"hardline\", \"having\", \"healthcare\", \"heart\", \"heavenly\", \"higher\", \"higher\", \"hilton\", \"hindu\", \"hispano\", \"historic\", \"home\", \"home\", \"home\", \"hong\", \"hong\", \"hostage\", \"hostages\", \"hostages\", \"hostages\", \"housing\", \"human\", \"ibm\", \"ibm\", \"ibm\", \"inc.\", \"inc.\", \"inc.\", \"inc.\", \"inc.\", \"inc.\", \"inc.\", \"inc.\", \"inc.\", \"inca\", \"includes\", \"increased\", \"india\", \"india\", \"indonesia\", \"indonesian\", \"inspections\", \"insurance\", \"intel\", \"intel\", \"intel\", \"intended\", \"internet\", \"internet\", \"internet\", \"internet\", \"introduced\", \"iran\", \"iran\", \"iran\", \"iraq\", \"iraq\", \"iraq\", \"iraq\", \"iraq\", \"iraq\", \"iraq\", \"iraqi\", \"iraqi\", \"iraqi\", \"iraqi\", \"islamic\", \"israelis\", \"issued\", \"ivory\", \"james\", \"jan.\", \"japan\", \"japan\", \"japan\", \"jardine\", \"jewish\", \"job\", \"job\", \"jobs\", \"john\", \"john\", \"john\", \"johnson\", \"jordan\", \"judge\", \"jury\", \"kabchi\", \"kahney\", \"kanoodle\", \"kent\", \"kicks\", \"kill\", \"kill\", \"killed\", \"killed\", \"killed\", \"killed\", \"king\", \"kingdom\", \"kobe\", \"kong\", \"kong\", \"krishna\", \"lab\", \"lafrentz\", \"lawsuits\", \"lebanon\", \"libraries\", \"list\", \"list\", \"list\", \"lloyd\", \"loath\", \"loss\", \"loss\", \"loss\", \"loss\", \"loss\", \"loss\", \"losses\", \"low\", \"m\", \"m\", \"m\", \"m\", \"machine\", \"machine\", \"maintain\", \"makers\", \"manipur\", \"manuscripts\", \"marsh\", \"martinsville\", \"maurice\", \"mayor\", \"members\", \"members\", \"meteor\", \"meters\", \"microsoft\", \"microsoft\", \"microsoft\", \"microsoft\", \"microsoft\", \"military\", \"military\", \"military\", \"military\", \"miller\", \"million\", \"million\", \"million\", \"million\", \"million\", \"million\", \"million\", \"minutes\", \"minutes\", \"moderate\", \"monday\", \"monday\", \"monday\", \"monday\", \"monday\", \"monday\", \"monday\", \"monetary\", \"monetary\", \"motley\", \"moves\", \"moyes\", \"music\", \"music\", \"muslims\", \"mylan\", \"mylan\", \"narrower\", \"nasa\", \"nasa\", \"nascar\", \"national\", \"national\", \"national\", \"national\", \"national\", \"national\", \"net\", \"network\", \"network\", \"network\", \"network\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"normal\", \"nuclear\", \"oct.\", \"oct.\", \"oct.\", \"october\", \"offices\", \"official\", \"official\", \"official\", \"officials\", \"officials\", \"officials\", \"officials\", \"officials\", \"offsets\", \"offside\", \"oil\", \"oil\", \"oil\", \"oil\", \"oil\", \"oil\", \"old\", \"old\", \"olivier\", \"online\", \"online\", \"opec\", \"open\", \"open\", \"open\", \"open\", \"open\", \"oracle\", \"ordered\", \"organizing\", \"original\", \"ousted\", \"ouster\", \"output\", \"overnight\", \"palestinian\", \"palestinian\", \"palestinian\", \"palestinian\", \"park\", \"party\", \"party\", \"party\", \"past\", \"past\", \"patch\", \"patch\", \"patent\", \"pavano\", \"payments\", \"pc\", \"pc\", \"peaks\", \"penn\", \"pension\", \"people\", \"people\", \"people\", \"people\", \"people\", \"people\", \"people\", \"peoplesoft\", \"petition\", \"petitioned\", \"phish\", \"physical\", \"pictures\", \"pistons\", \"plan\", \"plan\", \"plan\", \"players\", \"players\", \"plus\", \"police\", \"police\", \"political\", \"political\", \"positions\", \"post\", \"post\", \"preparations\", \"president\", \"president\", \"president\", \"president\", \"president\", \"press\", \"press\", \"press\", \"pretty\", \"prey\", \"price\", \"price\", \"price\", \"prices\", \"prices\", \"prices\", \"product\", \"products\", \"products\", \"products\", \"programs\", \"programs\", \"programs\", \"provisioning\", \"qaeda\", \"qaeda\", \"quarter\", \"quarter\", \"quarter\", \"quarter\", \"quarter\", \"quarter\", \"quarterfinals\", \"que\", \"quickinfo\", \"quickinfo\", \"quickinfo\", \"quot\", \"quot\", \"quot\", \"quot\", \"quot;beg\", \"radio\", \"rail\", \"rangers\", \"rangers\", \"rare\", \"realnetworks\", \"realnetworks\", \"rebel\", \"recent\", \"record\", \"record\", \"record\", \"record\", \"record\", \"regulate\", \"rejects\", \"remarks\", \"repaired\", \"report\", \"report\", \"report\", \"report\", \"report\", \"rescue\", \"resistance\", \"resistance\", \"result\", \"resuming\", \"reu\", \"reuters\", \"reuters\", \"reuters\", \"reuters\", \"reuters\", \"reuters\", \"rising\", \"robby\", \"ron\", \"rss\", \"rumsfeld\", \"run\", \"run\", \"run\", \"run\", \"running\", \"running\", \"said\", \"said\", \"said\", \"said\", \"said\", \"said\", \"said\", \"said\", \"said\", \"said\", \"sainsbury\", \"sales\", \"sales\", \"santander\", \"santander\", \"saturday\", \"saturday\", \"saturday\", \"saturday\", \"saturday\", \"says\", \"says\", \"says\", \"says\", \"says\", \"scribes\", \"search\", \"sector\", \"seeded\", \"seeded\", \"sees\", \"selection\", \"server\", \"server\", \"servers\", \"servers\", \"set\", \"set\", \"shanghai\", \"shanghai\", \"shares\", \"shares\", \"shares\", \"shares\", \"sharon\", \"shower\", \"shower\", \"shuttle\", \"shuttle\", \"signed\", \"signed\", \"skycity\", \"slightly\", \"slowdown\", \"slowed\", \"smell\", \"soccer\", \"soccer\", \"soccer\", \"soccer\", \"soft\", \"software\", \"software\", \"software\", \"software\", \"software\", \"soldiers\", \"sonic\", \"spacey\", \"spam\", \"state\", \"state\", \"state\", \"state\", \"state\", \"station\", \"step\", \"step\", \"step\", \"step\", \"stocks\", \"stocks\", \"stocks\", \"stocks\", \"stocks\", \"store\", \"store\", \"stoudemire\", \"strike\", \"strike\", \"strike\", \"struggling\", \"struggling\", \"sudan\", \"sudan\", \"sudan\", \"suicide\", \"summer\", \"sunday\", \"sunday\", \"sunday\", \"sunday\", \"sunday\", \"sunday\", \"super\", \"supporters\", \"surveillance\", \"systinet\", \"takeover\", \"takeover\", \"talks\", \"talks\", \"tax\", \"tb\", \"team\", \"team\", \"team\", \"team\", \"team\", \"technology\", \"technology\", \"technology\", \"technology\", \"textile\", \"thursday\", \"thursday\", \"thursday\", \"thursday\", \"thursday\", \"thursday\", \"ticker\", \"time\", \"time\", \"time\", \"time\", \"time\", \"tizbud\", \"today\", \"today\", \"today\", \"tokyo\", \"tokyo\", \"tokyo\", \"tokyo--(business\", \"tour\", \"tour\", \"transport\", \"tricks\", \"trophy\", \"trying\", \"trying\", \"tuesday\", \"tuesday\", \"tuesday\", \"tuesday\", \"tuesday\", \"u.s.\", \"u.s.\", \"u.s.\", \"u.s.\", \"u.s.\", \"ultimate\", \"ultimate\", \"unions\", \"unions\", \"unit\", \"united\", \"united\", \"united\", \"united\", \"united\", \"united\", \"unix\", \"unrestricted\", \"unusual\", \"utah\", \"utility\", \"vehicle\", \"vehicle\", \"vento\", \"veritas\", \"vic\", \"warner\", \"warner\", \"water\", \"weaknesses\", \"web\", \"web\", \"wednesday\", \"wednesday\", \"wednesday\", \"wednesday\", \"wednesday\", \"wednesday\", \"wednesday\", \"wednesday\", \"wednesday\", \"week\", \"week\", \"week\", \"week\", \"week\", \"wilkinson\", \"williams\", \"winning\", \"winning\", \"wireless\", \"worked\", \"worked\", \"world\", \"world\", \"world\", \"world\", \"world\", \"world\", \"world\", \"worsens\", \"wsj\", \"yahoo\", \"yankees\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"yesterday\", \"yesterday\", \"yesterday\", \"york\", \"york\", \"york\", \"york\", \"york\", \"yudhoyono\", \"yukos\", \"zook\", \"zte\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 10, 6, 2, 9, 4, 5, 8, 7, 3]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el12982140636666617520494848102\", ldavis_el12982140636666617520494848102_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el12982140636666617520494848102\", ldavis_el12982140636666617520494848102_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el12982140636666617520494848102\", ldavis_el12982140636666617520494848102_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "0     -0.116724 -0.025812       1        1  14.558275\n",
       "9     -0.080111 -0.030498       2        1  12.667915\n",
       "5     -0.067159  0.056382       3        1  12.286678\n",
       "1      0.036065  0.141419       4        1  10.865964\n",
       "8      0.034288  0.029135       5        1  10.287110\n",
       "3      0.091187 -0.080422       6        1   9.307491\n",
       "4      0.045166 -0.035006       7        1   7.940300\n",
       "7      0.039561 -0.023292       8        1   7.800703\n",
       "6      0.046642  0.015151       9        1   7.557558\n",
       "2     -0.028915 -0.047056      10        1   6.728006, topic_info=         Term       Freq      Total Category  logprob  loglift\n",
       "161            62.000000  62.000000  Default  30.0000  30.0000\n",
       "65         ap  21.000000  21.000000  Default  29.0000  29.0000\n",
       "1194     jobs   5.000000   5.000000  Default  28.0000  28.0000\n",
       "36       39;s  46.000000  46.000000  Default  27.0000  27.0000\n",
       "181   reuters  18.000000  18.000000  Default  26.0000  26.0000\n",
       "...       ...        ...        ...      ...      ...      ...\n",
       "17    tuesday   1.447159   9.370418  Topic10  -5.5030   0.8309\n",
       "163        al   1.180899   5.221428  Topic10  -5.7063   1.2124\n",
       "186      u.s.   1.248634  12.386983  Topic10  -5.6506   0.4043\n",
       "47       inc.   1.197293  10.145042  Topic10  -5.6925   0.5620\n",
       "16       said   1.186178  28.223641  Topic10  -5.7019  -0.4705\n",
       "\n",
       "[600 rows x 6 columns], token_table=      Topic      Freq       Term\n",
       "term                            \n",
       "161       1  0.368122           \n",
       "161       2  0.272090           \n",
       "161       3  0.128042           \n",
       "161       4  0.016005           \n",
       "161       5  0.080027           \n",
       "...     ...       ...        ...\n",
       "611       6  0.131956       york\n",
       "1981      1  0.929651  yudhoyono\n",
       "1863      4  0.490055      yukos\n",
       "160       8  0.530278       zook\n",
       "362       3  0.504879        zte\n",
       "\n",
       "[930 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[1, 10, 6, 2, 9, 4, 5, 8, 7, 3])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "##TODO using LDAvis visualize the topics using the optimal number of topics\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = gensimvis.prepare(lda10, common_corpus, dictionary=common_dictionary)\n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load and Pre-process Text\n",
    "We do sentiment analysis on the [Movie Review Data](https://www.cs.cornell.edu/people/pabo/movie-review-data/). If you would like to know more about the data, have a look at [the paper](https://www.cs.cornell.edu/home/llee/papers/pang-lee-stars.pdf) (but no need to do so)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-11-13 13:20:40--  https://www.cs.cornell.edu/people/pabo/movie-review-data/scale_data.tar.gz\n",
      "Resolving www.cs.cornell.edu (www.cs.cornell.edu)... 132.236.207.36\n",
      "Connecting to www.cs.cornell.edu (www.cs.cornell.edu)|132.236.207.36|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4029756 (3.8M) [application/x-gzip]\n",
      "Saving to: 'scale_data.tar.gz'\n",
      "\n",
      "scale_data.tar.gz   100%[===================>]   3.84M  3.21MB/s    in 1.2s    \n",
      "\n",
      "2022-11-13 13:20:43 (3.21 MB/s) - 'scale_data.tar.gz' saved [4029756/4029756]\n",
      "\n",
      "--2022-11-13 13:20:43--  https://www.cs.cornell.edu/people/pabo/movie-review-data/scale_whole_review.tar.gz\n",
      "Resolving www.cs.cornell.edu (www.cs.cornell.edu)... 132.236.207.36\n",
      "Connecting to www.cs.cornell.edu (www.cs.cornell.edu)|132.236.207.36|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 8853204 (8.4M) [application/x-gzip]\n",
      "Saving to: 'scale_whole_review.tar.gz'\n",
      "\n",
      "scale_whole_review. 100%[===================>]   8.44M  1.77MB/s    in 5.5s    \n",
      "\n",
      "2022-11-13 13:20:49 (1.54 MB/s) - 'scale_whole_review.tar.gz' saved [8853204/8853204]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# In this tutorial, we do sentiment analysis\n",
    "# download the data\n",
    "#!wget https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "#!tar xf aclImdb_v1.tar.gz\n",
    "\n",
    "!wget https://www.cs.cornell.edu/people/pabo/movie-review-data/scale_data.tar.gz\n",
    "!wget https://www.cs.cornell.edu/people/pabo/movie-review-data/scale_whole_review.tar.gz\n",
    " \n",
    "!tar xf scale_data.tar.gz \n",
    "!tar xf scale_whole_review.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we have to load the data for which we provide the function below. Note how we also preprocess the text using gensim's simple_preprocess() function and how we already split the data into a train and test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: bloody child the director writer cinematographer nina menkes screenwriter tinka menkes editors nina and tina menkes cast tinka menkes captain sherry sibley murdered wife robert mueller murderer russ little sergeant jack hara enlisted man runtime mirage reviewed by dennis schwartz an amazingly strange film confusing and not thoroughly enjoyable but film found more interesting than thought possible at first viewing this experimental film in minimalist story telling film consisting of disturbing visualizations and almost no dialogue had concept that was greater than how the film turned out it felt at times like was watching paint dry on the wall but the reward for sitting through those excruciatingly redundant scenes was in seeing something different something that cast spell of sorcery over terrible incident as believe the film in its unique and sometimes shrill voice does justice in commenting on the violence in american society especially against women the film uses its impressions of the marine base as metaphor for the social violence in today american society and to give it its startling look of reality marines were used as the actors it was filmed at twenty nine palms calif the largest marine base in the country which is located in the mojave desert the plot is simple it is about real incident that happened to marine returning from the persian gulf war who murdered his wife and was caught at sunrise digging her grave in the mojave desert by military patrol the film tells its story by showing the military police by the murder site making small talk while awaiting for the arrest to be completed and the marines off base relaxing in country and western lounge as some marines lewdly dance in front of some female patrons the film boredom is broken up by camera shots of marines in conversations that we can hear in its entirety but are treated to little snippets of hearing mostly their curse words the captain in charge of the arrest is tinka menkes the director sister she tries to get the male marines to take this incident seriously and act professional as they treat her as an outsider but with proper military respect because the film had no linear story and followed no chronological order and it stressed the mundaneness of life on the base and did not film its story in the usual way murder investigation is filmed it appeared surreal for whatever reason nina menkes the great sadness of zohara magdalena viraga queen of diamonds director am not familiar with has chosen to put parts of macbeth into the film the disembodied voice of the murdered wife is heard at times as the voice of violated spirit along with scenes from northeast africa tinka is sitting naked in the forest clearing writing unreadable words on her arm there is also riderless black horse going on the base and the film ends on quote from the book of genesis about lot wife turned into pillar of salt when she looked back thought these additions seemed to serve mostly as unneeded arty pretext the arrested marine is not seen in total but is viewed from side glances of him in the same car as his bloodied dead wife military policeman is seen shoving the marine face into his dead wife bloody lap and yelling some nearly inaudible obscenities at him the film tells nothing about the why and how of the murder but touches on the reality of life on the marine base making it seem like wasteland inhabited only by those sent to purgatory the unsettling milieu in which the crime took place speaks volumes about why the murder might have taken place the film seems to be telling us that it up to us to make sense of what we ve seen though the film was dull and did not move me while was watching it it did something to me afterwards intellectually it made me think of military base the persian gulf war and of marital abuse but it made me think of them without the usual concepts bring to my thinking cap does that make this great film no but it makes it an interesting one film that can easily dismiss its filming of the arrest is so chilling and memorable because what is so dull and ordinary about the crime scene is the understated reason for the origin of the violence contrary to the way hollywood films portray violence here it is part of the landscape that one regularly sees but perhaps one doesn really understand or want to understand what evil society has created reviewed on dennis schwartz ozus world movie reviews all rights reserved dennis schwartz \n",
      "label: 0.6\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from gensim.utils import simple_preprocess\n",
    "def load_data():\n",
    "    examples, labels = [], []\n",
    "    authors = os.listdir(\"scale_whole_review\")\n",
    "    for author in authors:\n",
    "        path = os.listdir(os.path.join(\"scale_whole_review\", author, \"txt.parag\"))\n",
    "        fn_ids = os.path.join(\"scaledata\", author, \"id.\" + author)\n",
    "        fn_ratings = os.path.join(\"scaledata\", author, \"rating.\" + author)\n",
    "        with open(fn_ids) as ids, open(fn_ratings) as ratings:\n",
    "            for idx, rating in zip(ids, ratings):\n",
    "                labels.append(float(rating.strip()))\n",
    "                filename_text = os.path.join(\"scale_whole_review\", author, \"txt.parag\", idx.strip() + \".txt\")\n",
    "                with open(filename_text, encoding='latin-1') as f:\n",
    "                    examples.append(\" \".join(simple_preprocess(f.read())))\n",
    "    return examples, labels\n",
    "                  \n",
    "X,y  = load_data()\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "print (\"text:\", X_train[0], \"\\nlabel:\", y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elliotbeck/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3354, 5593)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elliotbeck/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.info of       aaron  abandon  abandoned  abilities  ability  able  ably  aboard  \\\n",
      "0       0.0      0.0        0.0        0.0      0.0   0.0   0.0     0.0   \n",
      "1       0.0      0.0        0.0        0.0      0.0   0.0   0.0     0.0   \n",
      "2       0.0      0.0        0.0        0.0      0.0   0.0   0.0     0.0   \n",
      "3       0.0      0.0        0.0        0.0      0.0   0.0   0.0     0.0   \n",
      "4       0.0      0.0        0.0        0.0      0.0   0.0   0.0     0.0   \n",
      "...     ...      ...        ...        ...      ...   ...   ...     ...   \n",
      "1647    0.0      0.0        0.0        0.0      0.0   0.0   0.0     0.0   \n",
      "1648    0.0      0.0        0.0        0.0      0.0   0.0   0.0     0.0   \n",
      "1649    0.0      0.0        0.0        0.0      0.0   0.0   0.0     0.0   \n",
      "1650    0.0      0.0        0.0        0.0      0.0   0.0   0.0     0.0   \n",
      "1651    0.0      0.0        0.0        0.0      0.0   0.0   0.0     0.0   \n",
      "\n",
      "      absence  absent  ...  young girl  young man  young son  young woman  \\\n",
      "0         0.0     0.0  ...         0.0        0.0        0.0          0.0   \n",
      "1         0.0     0.0  ...         0.0        0.0        0.0          0.0   \n",
      "2         0.0     0.0  ...         0.0        0.0        0.0          0.0   \n",
      "3         0.0     0.0  ...         0.0        0.0        0.0          0.0   \n",
      "4         0.0     0.0  ...         0.0        0.0        0.0          0.0   \n",
      "...       ...     ...  ...         ...        ...        ...          ...   \n",
      "1647      0.0     0.0  ...         0.0        0.0        0.0          0.0   \n",
      "1648      0.0     0.0  ...         0.0        0.0        0.0          0.0   \n",
      "1649      0.0     0.0  ...         0.0        0.0        0.0          0.0   \n",
      "1650      0.0     0.0  ...         0.0        0.0        0.0          0.0   \n",
      "1651      0.0     0.0  ...         0.0        0.0        0.0          0.0   \n",
      "\n",
      "      younger  younger brother  youngest  youngster  youngsters  youth  \n",
      "0         0.0              0.0       0.0        0.0    0.000000    0.0  \n",
      "1         0.0              0.0       0.0        0.0    0.000000    0.0  \n",
      "2         0.0              0.0       0.0        0.0    0.000000    0.0  \n",
      "3         0.0              0.0       0.0        0.0    0.000000    0.0  \n",
      "4         0.0              0.0       0.0        0.0    0.000000    0.0  \n",
      "...       ...              ...       ...        ...         ...    ...  \n",
      "1647      0.0              0.0       0.0        0.0    0.000000    0.0  \n",
      "1648      0.0              0.0       0.0        0.0    0.000000    0.0  \n",
      "1649      0.0              0.0       0.0        0.0    0.000000    0.0  \n",
      "1650      0.0              0.0       0.0        0.0    0.068793    0.0  \n",
      "1651      0.0              0.0       0.0        0.0    0.000000    0.0  \n",
      "\n",
      "[1652 rows x 5593 columns]>\n"
     ]
    }
   ],
   "source": [
    "# train a TF_IDF Vectorizer on X_train and vectorize X_train and X_test\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vec = TfidfVectorizer(min_df=0.01, # at min 1% of docs\n",
    "                        max_df=.5,  \n",
    "                        stop_words='english',\n",
    "                        ngram_range=(1,2))\n",
    "\n",
    "##TODO train vectorizer\n",
    "vec.fit(X_train)\n",
    "\n",
    "##TODO transform X_train to TF-IDF values\n",
    "X_train_tfidf = vec.transform(X_train)\n",
    "feature_names = vec.get_feature_names()\n",
    "dense = X_train_tfidf.todense()\n",
    "lst1 = dense.tolist()\n",
    "X_train_tfidf = pd.DataFrame(lst1, columns=feature_names)\n",
    "print(X_train_tfidf.shape)\n",
    "\n",
    "##TODO transform X_test to TF-IDF values\n",
    "X_test_tfidf = vec.transform(X_test)\n",
    "feature_names = vec.get_feature_names()\n",
    "dense = X_test_tfidf.todense()\n",
    "lst1 = dense.tolist()\n",
    "X_test_tfidf = pd.DataFrame(lst1, columns=feature_names)\n",
    "print(X_test_tfidf.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO scale both training and test data with the standard scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "X_train_tfidf_scaled = scaler.fit_transform(X_train_tfidf)\n",
    "X_test_tfidf_scaled = scaler.transform(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49772890489643706 0.016535782264671527\n"
     ]
    }
   ],
   "source": [
    "##TODO train an elastic net on the transformed output of the scaler\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "en = ElasticNet(alpha=0.01)\n",
    "\n",
    "##TODO train the ElasticNet\n",
    "en.fit(X_train_tfidf_scaled, y_train)\n",
    "##TODO predict the testset\n",
    "preds = en.predict(X_test_tfidf_scaled)\n",
    "\n",
    "from sklearn.metrics import r2_score, accuracy_score, mean_squared_error, balanced_accuracy_score\n",
    "##TODO print mean squared error and r2 score on the test set\n",
    "r2 = r2_score(y_test, preds)\n",
    "# accur_score = accuracy_score(y_test, preds) doesn't work, we are not classifying\n",
    "mse = mean_squared_error(y_test, preds)\n",
    "# balanc_accur_score = balanced_accuracy_score(y_test, preds)\n",
    "print(r2, mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we train an OLS model doing binary prediction on these movie reviews. Two get two bins, we transform the continuous ratings into two classes, where one class contains all the negative ratings (value < 0.5), the other class all the positive ratings (value > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = [1 if i >= 0.5 else 0 for i in y_train]\n",
    "y_test = [1 if i >= 0.5 else 0 for i in y_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8075060532687651\n",
      "Index(['great', 'effective', 'surprisingly', 'punches', 'success',\n",
      "       'fascinating', 'influenced', 'investigating', 'brilliant', 'best'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elliotbeck/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "##TODO train logistic regression on X_train\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_regression = LogisticRegression()\n",
    "\n",
    "##TODO train a logistic regression\n",
    "logistic_regression.fit(X_train_tfidf_scaled, y_train)\n",
    "\n",
    "##TODO predict the testset \n",
    "preds = logistic_regression.predict(X_test_tfidf_scaled)\n",
    "\n",
    "##since we have continuous output, we need to post-process our labels into two classes. We choose a threshold of 0.5 \n",
    "def map_predictions(predicted):\n",
    "    predicted = [1 if i > 0.5 else 0 for i in predicted]\n",
    "    return predicted\n",
    "\n",
    "##TODO print the accuracy of our classifier on the testset\n",
    "print(accuracy_score(y_test, map_predictions(preds)))\n",
    "\n",
    "## TODO print the 10 most informative words of the regression (the 10 words having the highest coefficients)\n",
    "idx = (-logistic_regression.coef_).argsort()\n",
    "idx = idx[0][:10]\n",
    "print(X_train_tfidf.columns[idx])  # type: ignore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we train an XGBoost classifier to do topic prediction on the AG news dataset, which is a multi-class prediction problem (4 classes). We again have to vectorize the data, train the classifier, predict the testset and output an evaluation metric (we go for accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8f937451",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# vectorize the data\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# only consider 10% of the data\n",
    "dfs = df.sample(frac=0.1)\n",
    "\n",
    "# split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(dfs[\"text\"], dfs[\"label\"], test_size=0.33, random_state=42)\n",
    "\n",
    "vec = TfidfVectorizer(min_df=5, # at min 1% of docs\n",
    "                        max_df=.5,  \n",
    "                        stop_words='english',\n",
    "                        max_features=2000,\n",
    "                        ngram_range=(1,2))\n",
    "\n",
    "# transform into TF-IDF values\n",
    "X_train_tfidf = vec.fit_transform(X_train).todense()\n",
    "X_test_tfidf = vec.transform(X_test).todense()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost provides an interface to SKLearn classifiers, e.g. they implement the same train and predict methods as an SKLearn classifier would. If you are interested in a more detailed overview, have a look at the [official documentation](https://xgboost.readthedocs.io/en/latest/python/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.806060606060606\n"
     ]
    }
   ],
   "source": [
    "param_dist = {'objective':'multi:softmax', 'num_class': 5, 'n_estimators':25}\n",
    "# note how we only have 4 labels, but we need to pass \"num_class\": 5\n",
    "# if we pass \"num_class\": 4, we get the error \"label must be in [0, num_class).\"\n",
    "import xgboost as xgb\n",
    "from sklearn import preprocessing\n",
    "\n",
    "clf = xgb.XGBModel(**param_dist)\n",
    "\n",
    "##TODO train the XGBModel \n",
    "le = preprocessing.LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "##TODO predict the testset \n",
    "preds = clf.predict(X_test_tfidf)\n",
    "\n",
    "##TODO evaluate the predictions using accuracy as a metric\n",
    "le = preprocessing.LabelEncoder()\n",
    "y_test = le.fit_transform(y_test)\n",
    "print(accuracy_score(y_test, preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Oct 13 2022, 16:12:30) \n[Clang 12.0.0 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "7847a2e259535c6ee3594af5f07a48848165b814e08df174595330ed14ca1dac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
